{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d30abe48-ffca-4365-9e1e-e1f493dedd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load MELD test set\n",
    "test_df = pd.read_csv(\"data/test_sent_emo.csv\")\n",
    "\n",
    "# Load generated responses CHANGE THIS PATH\n",
    "gen_df = pd.read_csv(\"results/mistral_baseline.csv\")\n",
    "\n",
    "# Sort for safety\n",
    "test_df.sort_values(by=[\"Dialogue_ID\", \"Utterance_ID\"], inplace=True)\n",
    "gen_df.sort_values(by=[\"Dialogue_ID\", \"Utterance_ID\"], inplace=True)\n",
    "\n",
    "# Output list\n",
    "output = []\n",
    "\n",
    "# Group MELD test by Dialogue_ID\n",
    "grouped = test_df.groupby(\"Dialogue_ID\")\n",
    "\n",
    "# Iterate over each dialogue\n",
    "for dialogue_id, group in grouped:\n",
    "    dialogue = group.sort_values(\"Utterance_ID\")\n",
    "\n",
    "    history_utterances = []\n",
    "    history_emotions = []\n",
    "    history_sentiments = []\n",
    "\n",
    "    for _, row in dialogue.iterrows():\n",
    "        utterance_id = int(row[\"Utterance_ID\"])\n",
    "        speaker = row[\"Speaker\"]\n",
    "        utterance = row[\"Utterance\"]\n",
    "        emotion = row[\"Emotion\"]\n",
    "        sentiment = row[\"Sentiment\"]\n",
    "\n",
    "        # Format speaker utterance\n",
    "        formatted_utterance = f\"{speaker}: {utterance}\"\n",
    "        history_utterances.append(formatted_utterance)\n",
    "        history_emotions.append(emotion)\n",
    "        history_sentiments.append(sentiment)\n",
    "\n",
    "        # Match the generated response\n",
    "        match = gen_df[\n",
    "            (gen_df[\"Dialogue_ID\"] == dialogue_id) &\n",
    "            (gen_df[\"Utterance_ID\"] == utterance_id)\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            generated_response = match.iloc[0][\"Response\"]\n",
    "        else:\n",
    "            generated_response = \"\"\n",
    "\n",
    "        output.append({\n",
    "            \"dialogue_id\": dialogue_id,\n",
    "            \"utterance_id\": utterance_id,\n",
    "            \"generated_response\": generated_response,\n",
    "            \"history_utterances\": history_utterances.copy(),\n",
    "            \"history_emotions\": history_emotions.copy(),\n",
    "            \"history_sentiments\": history_sentiments.copy()\n",
    "        })\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"empathy\", exist_ok=True)\n",
    "\n",
    "# Save to JSONL\n",
    "with open(\"empathy/mistral_baseline/dialogue_generations.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in output:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09b6ad-5c9a-42a0-8af9-d0057cb6762c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b3cd97-e87d-41b1-a217-6aca05492ae8",
   "metadata": {},
   "source": [
    "# Load Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3d182-10a0-4418-97a3-18800cc1ba85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from finetune_mllm import EmpatheticMLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c26c1e-89a9-48c5-9902-ed6b4dbc43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EmpatheticMLLM()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a81623f-8911-458d-8bc4-33f0097cbd13",
   "metadata": {},
   "source": [
    "# Generate Responses for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387490f7-ffd3-4fce-8b0e-d6ba8bff378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune_mllm import prepare_split, MultimodalMELD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_data = prepare_split('dev')\n",
    "test_dataset = MultimodalMELD(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4bcdd-c27b-4553-94fc-1ece3bf53aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "generated_responses = []\n",
    "target_responses = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        x = {\n",
    "            'text': batch['text'],\n",
    "            'audio': batch['audio'],\n",
    "            'video': batch['video']\n",
    "        }\n",
    "\n",
    "        generation_config = GenerationConfig(\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95\n",
    "        )\n",
    "\n",
    "        responses = model.generate(x, generation_config)\n",
    "        print(responses)\n",
    "        generated_responses.append(responses)\n",
    "        target_responses.append(batch['target_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4965be94-4701-4786-957f-9bf2c8a65a2c",
   "metadata": {},
   "source": [
    "# Calculate BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e891f-4c32-4208-9c18-fca4852dfd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "P, R, F1 = score(generated_responses, target_responses, lang=\"en\")\n",
    "\n",
    "print(f\"PBERT: {P.mean():.4f}\")\n",
    "print(f\"RBERT: {R.mean():.4f}\")\n",
    "print(f\"FBERT: {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5d56e-cb30-460f-9c4f-b76904717796",
   "metadata": {},
   "source": [
    "# Calculate Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519da4e-393b-4b8f-bd03-03331599e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate PPL on ground-truth target responses\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "ppl_list = []\n",
    "for response in target_responses:\n",
    "    input_ids = tokenizer.encode(response, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.llm(input_ids, labels=input_ids)\n",
    "    loss = outputs.loss\n",
    "    ppl = math.exp(loss.item())\n",
    "    ppl_list.append(ppl)\n",
    "print(f\"PPL: {sum(ppl_list) / len(ppl_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8416ad-4140-46ea-b3cc-4b4226e7851a",
   "metadata": {},
   "source": [
    "# Calculate Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27288628-b0cc-4191-bbb2-a9ce7a98ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "def compute_dist_n(responses, n):\n",
    "    all_ngrams = []\n",
    "    for response in responses:\n",
    "        tokens = response.split()\n",
    "        all_ngrams.extend(ngrams(tokens, n))\n",
    "    total = len(all_ngrams)\n",
    "    unique = len(set(all_ngrams))\n",
    "    return unique / total if total > 0 else 0\n",
    "\n",
    "dist1 = compute_dist_n(generated_responses, 1)\n",
    "dist2 = compute_dist_n(generated_responses, 2)\n",
    "\n",
    "print(f\"Dist-1: {dist1:.4f}\")\n",
    "print(f\"Dist-2: {dist2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

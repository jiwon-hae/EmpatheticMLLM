{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 7494,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0040032025620496394,
      "grad_norm": 0.24535970389842987,
      "learning_rate": 4.9933279957299176e-05,
      "loss": 3.4778,
      "step": 10
    },
    {
      "epoch": 0.008006405124099279,
      "grad_norm": 0.26465120911598206,
      "learning_rate": 4.986655991459835e-05,
      "loss": 3.3546,
      "step": 20
    },
    {
      "epoch": 0.01200960768614892,
      "grad_norm": 0.2993769645690918,
      "learning_rate": 4.979983987189752e-05,
      "loss": 3.3669,
      "step": 30
    },
    {
      "epoch": 0.016012810248198558,
      "grad_norm": 0.38173606991767883,
      "learning_rate": 4.9733119829196695e-05,
      "loss": 3.4142,
      "step": 40
    },
    {
      "epoch": 0.020016012810248198,
      "grad_norm": 0.6845929622650146,
      "learning_rate": 4.966639978649587e-05,
      "loss": 3.3099,
      "step": 50
    },
    {
      "epoch": 0.02401921537229784,
      "grad_norm": 0.6117146015167236,
      "learning_rate": 4.959967974379504e-05,
      "loss": 3.2685,
      "step": 60
    },
    {
      "epoch": 0.02802241793434748,
      "grad_norm": 0.5402461886405945,
      "learning_rate": 4.9532959701094215e-05,
      "loss": 3.3674,
      "step": 70
    },
    {
      "epoch": 0.032025620496397116,
      "grad_norm": 0.392112672328949,
      "learning_rate": 4.946623965839338e-05,
      "loss": 3.2064,
      "step": 80
    },
    {
      "epoch": 0.036028823058446756,
      "grad_norm": 0.44459524750709534,
      "learning_rate": 4.9399519615692554e-05,
      "loss": 3.085,
      "step": 90
    },
    {
      "epoch": 0.040032025620496396,
      "grad_norm": 0.4710959792137146,
      "learning_rate": 4.933279957299173e-05,
      "loss": 3.1149,
      "step": 100
    },
    {
      "epoch": 0.044035228182546036,
      "grad_norm": 0.49170586466789246,
      "learning_rate": 4.92660795302909e-05,
      "loss": 3.0142,
      "step": 110
    },
    {
      "epoch": 0.04803843074459568,
      "grad_norm": 0.445470929145813,
      "learning_rate": 4.9199359487590074e-05,
      "loss": 3.0605,
      "step": 120
    },
    {
      "epoch": 0.05204163330664532,
      "grad_norm": 0.6807774901390076,
      "learning_rate": 4.913263944488925e-05,
      "loss": 3.0366,
      "step": 130
    },
    {
      "epoch": 0.05604483586869496,
      "grad_norm": 0.6901031136512756,
      "learning_rate": 4.906591940218842e-05,
      "loss": 2.9341,
      "step": 140
    },
    {
      "epoch": 0.0600480384307446,
      "grad_norm": 0.5056790113449097,
      "learning_rate": 4.8999199359487594e-05,
      "loss": 2.8337,
      "step": 150
    },
    {
      "epoch": 0.06405124099279423,
      "grad_norm": 0.8417543172836304,
      "learning_rate": 4.893247931678677e-05,
      "loss": 2.7945,
      "step": 160
    },
    {
      "epoch": 0.06805444355484387,
      "grad_norm": 0.6394469141960144,
      "learning_rate": 4.886575927408594e-05,
      "loss": 2.63,
      "step": 170
    },
    {
      "epoch": 0.07205764611689351,
      "grad_norm": 0.8086075186729431,
      "learning_rate": 4.879903923138511e-05,
      "loss": 2.6853,
      "step": 180
    },
    {
      "epoch": 0.07606084867894315,
      "grad_norm": 0.548653244972229,
      "learning_rate": 4.8732319188684286e-05,
      "loss": 2.5757,
      "step": 190
    },
    {
      "epoch": 0.08006405124099279,
      "grad_norm": 0.5913213491439819,
      "learning_rate": 4.866559914598345e-05,
      "loss": 2.5401,
      "step": 200
    },
    {
      "epoch": 0.08406725380304243,
      "grad_norm": 0.8041505813598633,
      "learning_rate": 4.859887910328263e-05,
      "loss": 2.5103,
      "step": 210
    },
    {
      "epoch": 0.08807045636509207,
      "grad_norm": 0.5867807865142822,
      "learning_rate": 4.85321590605818e-05,
      "loss": 2.408,
      "step": 220
    },
    {
      "epoch": 0.09207365892714171,
      "grad_norm": 0.8996674418449402,
      "learning_rate": 4.846543901788098e-05,
      "loss": 2.3297,
      "step": 230
    },
    {
      "epoch": 0.09607686148919135,
      "grad_norm": 0.9448404312133789,
      "learning_rate": 4.8398718975180146e-05,
      "loss": 2.2038,
      "step": 240
    },
    {
      "epoch": 0.100080064051241,
      "grad_norm": 0.7715282440185547,
      "learning_rate": 4.833199893247932e-05,
      "loss": 2.2006,
      "step": 250
    },
    {
      "epoch": 0.10408326661329063,
      "grad_norm": 0.8269147872924805,
      "learning_rate": 4.826527888977849e-05,
      "loss": 2.1048,
      "step": 260
    },
    {
      "epoch": 0.10808646917534027,
      "grad_norm": 1.0901563167572021,
      "learning_rate": 4.8198558847077665e-05,
      "loss": 2.1164,
      "step": 270
    },
    {
      "epoch": 0.11208967173738991,
      "grad_norm": 0.6093773245811462,
      "learning_rate": 4.813183880437684e-05,
      "loss": 2.0114,
      "step": 280
    },
    {
      "epoch": 0.11609287429943956,
      "grad_norm": 1.0089374780654907,
      "learning_rate": 4.806511876167601e-05,
      "loss": 1.9519,
      "step": 290
    },
    {
      "epoch": 0.1200960768614892,
      "grad_norm": 0.8092987537384033,
      "learning_rate": 4.7998398718975185e-05,
      "loss": 1.9085,
      "step": 300
    },
    {
      "epoch": 0.12409927942353884,
      "grad_norm": 0.8435871601104736,
      "learning_rate": 4.793167867627436e-05,
      "loss": 1.9364,
      "step": 310
    },
    {
      "epoch": 0.12810248198558846,
      "grad_norm": 0.6196471452713013,
      "learning_rate": 4.7864958633573524e-05,
      "loss": 1.9136,
      "step": 320
    },
    {
      "epoch": 0.1321056845476381,
      "grad_norm": 0.6231955289840698,
      "learning_rate": 4.7798238590872704e-05,
      "loss": 1.8402,
      "step": 330
    },
    {
      "epoch": 0.13610888710968774,
      "grad_norm": 1.5335659980773926,
      "learning_rate": 4.773151854817187e-05,
      "loss": 1.843,
      "step": 340
    },
    {
      "epoch": 0.14011208967173738,
      "grad_norm": 0.9025129079818726,
      "learning_rate": 4.766479850547105e-05,
      "loss": 1.7998,
      "step": 350
    },
    {
      "epoch": 0.14411529223378702,
      "grad_norm": 0.8335690498352051,
      "learning_rate": 4.759807846277022e-05,
      "loss": 1.7352,
      "step": 360
    },
    {
      "epoch": 0.14811849479583666,
      "grad_norm": 0.7187110781669617,
      "learning_rate": 4.753135842006939e-05,
      "loss": 1.6642,
      "step": 370
    },
    {
      "epoch": 0.1521216973578863,
      "grad_norm": 0.9156674742698669,
      "learning_rate": 4.7464638377368564e-05,
      "loss": 1.7793,
      "step": 380
    },
    {
      "epoch": 0.15612489991993594,
      "grad_norm": 0.8289965391159058,
      "learning_rate": 4.739791833466774e-05,
      "loss": 1.6411,
      "step": 390
    },
    {
      "epoch": 0.16012810248198558,
      "grad_norm": 0.8025514483451843,
      "learning_rate": 4.733119829196691e-05,
      "loss": 1.6513,
      "step": 400
    },
    {
      "epoch": 0.16413130504403523,
      "grad_norm": 0.7274012565612793,
      "learning_rate": 4.726447824926608e-05,
      "loss": 1.7443,
      "step": 410
    },
    {
      "epoch": 0.16813450760608487,
      "grad_norm": 0.8532120585441589,
      "learning_rate": 4.7197758206565256e-05,
      "loss": 1.7227,
      "step": 420
    },
    {
      "epoch": 0.1721377101681345,
      "grad_norm": 1.1492736339569092,
      "learning_rate": 4.713103816386443e-05,
      "loss": 1.58,
      "step": 430
    },
    {
      "epoch": 0.17614091273018415,
      "grad_norm": 1.0331614017486572,
      "learning_rate": 4.7064318121163596e-05,
      "loss": 1.7441,
      "step": 440
    },
    {
      "epoch": 0.1801441152922338,
      "grad_norm": 1.0316503047943115,
      "learning_rate": 4.6997598078462776e-05,
      "loss": 1.5948,
      "step": 450
    },
    {
      "epoch": 0.18414731785428343,
      "grad_norm": 0.8439592719078064,
      "learning_rate": 4.693087803576194e-05,
      "loss": 1.564,
      "step": 460
    },
    {
      "epoch": 0.18815052041633307,
      "grad_norm": 0.9670655131340027,
      "learning_rate": 4.686415799306112e-05,
      "loss": 1.5067,
      "step": 470
    },
    {
      "epoch": 0.1921537229783827,
      "grad_norm": 0.5561319589614868,
      "learning_rate": 4.679743795036029e-05,
      "loss": 1.5953,
      "step": 480
    },
    {
      "epoch": 0.19615692554043235,
      "grad_norm": 0.6574220657348633,
      "learning_rate": 4.673071790765947e-05,
      "loss": 1.6084,
      "step": 490
    },
    {
      "epoch": 0.200160128102482,
      "grad_norm": 0.785028874874115,
      "learning_rate": 4.6663997864958635e-05,
      "loss": 1.5871,
      "step": 500
    },
    {
      "epoch": 0.20416333066453163,
      "grad_norm": 0.5878079533576965,
      "learning_rate": 4.659727782225781e-05,
      "loss": 1.5393,
      "step": 510
    },
    {
      "epoch": 0.20816653322658127,
      "grad_norm": 0.6013811230659485,
      "learning_rate": 4.653055777955698e-05,
      "loss": 1.7404,
      "step": 520
    },
    {
      "epoch": 0.2121697357886309,
      "grad_norm": 0.9050463438034058,
      "learning_rate": 4.6463837736856155e-05,
      "loss": 1.6812,
      "step": 530
    },
    {
      "epoch": 0.21617293835068055,
      "grad_norm": 0.5617972016334534,
      "learning_rate": 4.639711769415533e-05,
      "loss": 1.6567,
      "step": 540
    },
    {
      "epoch": 0.2201761409127302,
      "grad_norm": 0.5776463150978088,
      "learning_rate": 4.63303976514545e-05,
      "loss": 1.7854,
      "step": 550
    },
    {
      "epoch": 0.22417934347477983,
      "grad_norm": 0.48262539505958557,
      "learning_rate": 4.626367760875367e-05,
      "loss": 1.6835,
      "step": 560
    },
    {
      "epoch": 0.22818254603682947,
      "grad_norm": 0.557475745677948,
      "learning_rate": 4.619695756605285e-05,
      "loss": 1.4633,
      "step": 570
    },
    {
      "epoch": 0.2321857485988791,
      "grad_norm": 0.6083614826202393,
      "learning_rate": 4.6130237523352014e-05,
      "loss": 1.577,
      "step": 580
    },
    {
      "epoch": 0.23618895116092875,
      "grad_norm": 0.5369415283203125,
      "learning_rate": 4.6063517480651194e-05,
      "loss": 1.5143,
      "step": 590
    },
    {
      "epoch": 0.2401921537229784,
      "grad_norm": 0.5933712124824524,
      "learning_rate": 4.599679743795036e-05,
      "loss": 1.4866,
      "step": 600
    },
    {
      "epoch": 0.24419535628502803,
      "grad_norm": 0.9974930882453918,
      "learning_rate": 4.593007739524954e-05,
      "loss": 1.6076,
      "step": 610
    },
    {
      "epoch": 0.24819855884707767,
      "grad_norm": 0.4792153835296631,
      "learning_rate": 4.586335735254871e-05,
      "loss": 1.572,
      "step": 620
    },
    {
      "epoch": 0.2522017614091273,
      "grad_norm": 0.4265930652618408,
      "learning_rate": 4.579663730984788e-05,
      "loss": 1.704,
      "step": 630
    },
    {
      "epoch": 0.2562049639711769,
      "grad_norm": 0.5882405042648315,
      "learning_rate": 4.572991726714705e-05,
      "loss": 1.5942,
      "step": 640
    },
    {
      "epoch": 0.2602081665332266,
      "grad_norm": 0.5840581655502319,
      "learning_rate": 4.5663197224446227e-05,
      "loss": 1.6257,
      "step": 650
    },
    {
      "epoch": 0.2642113690952762,
      "grad_norm": 0.7992194890975952,
      "learning_rate": 4.55964771817454e-05,
      "loss": 1.5939,
      "step": 660
    },
    {
      "epoch": 0.2682145716573259,
      "grad_norm": 0.5727997422218323,
      "learning_rate": 4.552975713904457e-05,
      "loss": 1.4867,
      "step": 670
    },
    {
      "epoch": 0.2722177742193755,
      "grad_norm": 0.7325592041015625,
      "learning_rate": 4.546303709634374e-05,
      "loss": 1.4221,
      "step": 680
    },
    {
      "epoch": 0.27622097678142515,
      "grad_norm": 0.5299435257911682,
      "learning_rate": 4.539631705364292e-05,
      "loss": 1.5839,
      "step": 690
    },
    {
      "epoch": 0.28022417934347477,
      "grad_norm": 0.6954792737960815,
      "learning_rate": 4.5329597010942086e-05,
      "loss": 1.566,
      "step": 700
    },
    {
      "epoch": 0.28422738190552443,
      "grad_norm": 0.4987212121486664,
      "learning_rate": 4.5262876968241266e-05,
      "loss": 1.5744,
      "step": 710
    },
    {
      "epoch": 0.28823058446757405,
      "grad_norm": 0.4466502368450165,
      "learning_rate": 4.519615692554043e-05,
      "loss": 1.5377,
      "step": 720
    },
    {
      "epoch": 0.2922337870296237,
      "grad_norm": 0.5167382955551147,
      "learning_rate": 4.512943688283961e-05,
      "loss": 1.6864,
      "step": 730
    },
    {
      "epoch": 0.2962369895916733,
      "grad_norm": 0.5436244010925293,
      "learning_rate": 4.506271684013878e-05,
      "loss": 1.6328,
      "step": 740
    },
    {
      "epoch": 0.300240192153723,
      "grad_norm": 0.592400312423706,
      "learning_rate": 4.499599679743795e-05,
      "loss": 1.4857,
      "step": 750
    },
    {
      "epoch": 0.3042433947157726,
      "grad_norm": 0.5512914061546326,
      "learning_rate": 4.4929276754737125e-05,
      "loss": 1.456,
      "step": 760
    },
    {
      "epoch": 0.3082465972778223,
      "grad_norm": 0.4824970066547394,
      "learning_rate": 4.48625567120363e-05,
      "loss": 1.4704,
      "step": 770
    },
    {
      "epoch": 0.3122497998398719,
      "grad_norm": 0.6729341149330139,
      "learning_rate": 4.479583666933547e-05,
      "loss": 1.5186,
      "step": 780
    },
    {
      "epoch": 0.31625300240192156,
      "grad_norm": 0.4024340808391571,
      "learning_rate": 4.4729116626634645e-05,
      "loss": 1.5085,
      "step": 790
    },
    {
      "epoch": 0.32025620496397117,
      "grad_norm": 0.6008446216583252,
      "learning_rate": 4.466239658393381e-05,
      "loss": 1.6139,
      "step": 800
    },
    {
      "epoch": 0.32425940752602084,
      "grad_norm": 0.5340154767036438,
      "learning_rate": 4.459567654123299e-05,
      "loss": 1.6407,
      "step": 810
    },
    {
      "epoch": 0.32826261008807045,
      "grad_norm": 0.6197512745857239,
      "learning_rate": 4.452895649853216e-05,
      "loss": 1.5197,
      "step": 820
    },
    {
      "epoch": 0.3322658126501201,
      "grad_norm": 0.6365818381309509,
      "learning_rate": 4.446223645583134e-05,
      "loss": 1.6124,
      "step": 830
    },
    {
      "epoch": 0.33626901521216973,
      "grad_norm": 0.6466824412345886,
      "learning_rate": 4.4395516413130504e-05,
      "loss": 1.5608,
      "step": 840
    },
    {
      "epoch": 0.3402722177742194,
      "grad_norm": 0.4022682011127472,
      "learning_rate": 4.4328796370429684e-05,
      "loss": 1.5141,
      "step": 850
    },
    {
      "epoch": 0.344275420336269,
      "grad_norm": 0.5131042003631592,
      "learning_rate": 4.426207632772885e-05,
      "loss": 1.6677,
      "step": 860
    },
    {
      "epoch": 0.3482786228983187,
      "grad_norm": 0.5131762027740479,
      "learning_rate": 4.419535628502802e-05,
      "loss": 1.388,
      "step": 870
    },
    {
      "epoch": 0.3522818254603683,
      "grad_norm": 0.40808847546577454,
      "learning_rate": 4.4128636242327197e-05,
      "loss": 1.5394,
      "step": 880
    },
    {
      "epoch": 0.35628502802241796,
      "grad_norm": 0.44633767008781433,
      "learning_rate": 4.406191619962637e-05,
      "loss": 1.5037,
      "step": 890
    },
    {
      "epoch": 0.3602882305844676,
      "grad_norm": 0.4893871247768402,
      "learning_rate": 4.399519615692554e-05,
      "loss": 1.4758,
      "step": 900
    },
    {
      "epoch": 0.36429143314651724,
      "grad_norm": 0.4828609824180603,
      "learning_rate": 4.3928476114224716e-05,
      "loss": 1.5124,
      "step": 910
    },
    {
      "epoch": 0.36829463570856685,
      "grad_norm": 0.4744313955307007,
      "learning_rate": 4.386175607152388e-05,
      "loss": 1.5571,
      "step": 920
    },
    {
      "epoch": 0.37229783827061647,
      "grad_norm": 0.5354211330413818,
      "learning_rate": 4.379503602882306e-05,
      "loss": 1.4885,
      "step": 930
    },
    {
      "epoch": 0.37630104083266613,
      "grad_norm": 0.6258930563926697,
      "learning_rate": 4.372831598612223e-05,
      "loss": 1.5423,
      "step": 940
    },
    {
      "epoch": 0.38030424339471575,
      "grad_norm": 0.6680314540863037,
      "learning_rate": 4.366159594342141e-05,
      "loss": 1.477,
      "step": 950
    },
    {
      "epoch": 0.3843074459567654,
      "grad_norm": 0.4537642300128937,
      "learning_rate": 4.3594875900720575e-05,
      "loss": 1.5438,
      "step": 960
    },
    {
      "epoch": 0.388310648518815,
      "grad_norm": 0.4705132246017456,
      "learning_rate": 4.3528155858019755e-05,
      "loss": 1.6448,
      "step": 970
    },
    {
      "epoch": 0.3923138510808647,
      "grad_norm": 0.47830769419670105,
      "learning_rate": 4.346143581531892e-05,
      "loss": 1.467,
      "step": 980
    },
    {
      "epoch": 0.3963170536429143,
      "grad_norm": 0.5337472558021545,
      "learning_rate": 4.3394715772618095e-05,
      "loss": 1.4271,
      "step": 990
    },
    {
      "epoch": 0.400320256204964,
      "grad_norm": 0.5014439225196838,
      "learning_rate": 4.332799572991727e-05,
      "loss": 1.5319,
      "step": 1000
    },
    {
      "epoch": 0.4043234587670136,
      "grad_norm": 0.38086584210395813,
      "learning_rate": 4.326127568721644e-05,
      "loss": 1.4215,
      "step": 1010
    },
    {
      "epoch": 0.40832666132906326,
      "grad_norm": 0.5082393884658813,
      "learning_rate": 4.3194555644515615e-05,
      "loss": 1.3686,
      "step": 1020
    },
    {
      "epoch": 0.41232986389111287,
      "grad_norm": 0.5727434158325195,
      "learning_rate": 4.312783560181479e-05,
      "loss": 1.4887,
      "step": 1030
    },
    {
      "epoch": 0.41633306645316254,
      "grad_norm": 0.4697447717189789,
      "learning_rate": 4.306111555911396e-05,
      "loss": 1.5422,
      "step": 1040
    },
    {
      "epoch": 0.42033626901521215,
      "grad_norm": 0.5012974739074707,
      "learning_rate": 4.2994395516413134e-05,
      "loss": 1.6872,
      "step": 1050
    },
    {
      "epoch": 0.4243394715772618,
      "grad_norm": 0.43096479773521423,
      "learning_rate": 4.29276754737123e-05,
      "loss": 1.591,
      "step": 1060
    },
    {
      "epoch": 0.42834267413931143,
      "grad_norm": 0.43960151076316833,
      "learning_rate": 4.286095543101148e-05,
      "loss": 1.4478,
      "step": 1070
    },
    {
      "epoch": 0.4323458767013611,
      "grad_norm": 0.5400107502937317,
      "learning_rate": 4.279423538831065e-05,
      "loss": 1.5181,
      "step": 1080
    },
    {
      "epoch": 0.4363490792634107,
      "grad_norm": 0.4821297526359558,
      "learning_rate": 4.272751534560983e-05,
      "loss": 1.4852,
      "step": 1090
    },
    {
      "epoch": 0.4403522818254604,
      "grad_norm": 0.6434522271156311,
      "learning_rate": 4.2660795302908993e-05,
      "loss": 1.4006,
      "step": 1100
    },
    {
      "epoch": 0.44435548438751,
      "grad_norm": 0.5193401575088501,
      "learning_rate": 4.2594075260208167e-05,
      "loss": 1.3954,
      "step": 1110
    },
    {
      "epoch": 0.44835868694955966,
      "grad_norm": 0.3897687792778015,
      "learning_rate": 4.252735521750734e-05,
      "loss": 1.5014,
      "step": 1120
    },
    {
      "epoch": 0.45236188951160927,
      "grad_norm": 0.5371881127357483,
      "learning_rate": 4.246063517480651e-05,
      "loss": 1.3838,
      "step": 1130
    },
    {
      "epoch": 0.45636509207365894,
      "grad_norm": 0.5936519503593445,
      "learning_rate": 4.2393915132105686e-05,
      "loss": 1.5216,
      "step": 1140
    },
    {
      "epoch": 0.46036829463570855,
      "grad_norm": 0.616481363773346,
      "learning_rate": 4.232719508940486e-05,
      "loss": 1.497,
      "step": 1150
    },
    {
      "epoch": 0.4643714971977582,
      "grad_norm": 0.46708863973617554,
      "learning_rate": 4.226047504670403e-05,
      "loss": 1.5658,
      "step": 1160
    },
    {
      "epoch": 0.46837469975980783,
      "grad_norm": 0.4599936604499817,
      "learning_rate": 4.2193755004003206e-05,
      "loss": 1.3171,
      "step": 1170
    },
    {
      "epoch": 0.4723779023218575,
      "grad_norm": 0.5104519128799438,
      "learning_rate": 4.212703496130237e-05,
      "loss": 1.6175,
      "step": 1180
    },
    {
      "epoch": 0.4763811048839071,
      "grad_norm": 0.5879703164100647,
      "learning_rate": 4.206031491860155e-05,
      "loss": 1.5331,
      "step": 1190
    },
    {
      "epoch": 0.4803843074459568,
      "grad_norm": 0.4778038561344147,
      "learning_rate": 4.199359487590072e-05,
      "loss": 1.5336,
      "step": 1200
    },
    {
      "epoch": 0.4843875100080064,
      "grad_norm": 0.4606799781322479,
      "learning_rate": 4.19268748331999e-05,
      "loss": 1.5962,
      "step": 1210
    },
    {
      "epoch": 0.48839071257005606,
      "grad_norm": 0.5052036046981812,
      "learning_rate": 4.1860154790499065e-05,
      "loss": 1.5455,
      "step": 1220
    },
    {
      "epoch": 0.4923939151321057,
      "grad_norm": 0.4630484879016876,
      "learning_rate": 4.179343474779824e-05,
      "loss": 1.4249,
      "step": 1230
    },
    {
      "epoch": 0.49639711769415534,
      "grad_norm": 0.4437594413757324,
      "learning_rate": 4.172671470509741e-05,
      "loss": 1.4531,
      "step": 1240
    },
    {
      "epoch": 0.500400320256205,
      "grad_norm": 0.4142501652240753,
      "learning_rate": 4.1659994662396585e-05,
      "loss": 1.3821,
      "step": 1250
    },
    {
      "epoch": 0.5044035228182546,
      "grad_norm": 0.5717626214027405,
      "learning_rate": 4.159327461969576e-05,
      "loss": 1.3161,
      "step": 1260
    },
    {
      "epoch": 0.5084067253803043,
      "grad_norm": 0.48345088958740234,
      "learning_rate": 4.152655457699493e-05,
      "loss": 1.4843,
      "step": 1270
    },
    {
      "epoch": 0.5124099279423538,
      "grad_norm": 0.5421435832977295,
      "learning_rate": 4.1459834534294104e-05,
      "loss": 1.5973,
      "step": 1280
    },
    {
      "epoch": 0.5164131305044035,
      "grad_norm": 0.3933057487010956,
      "learning_rate": 4.139311449159328e-05,
      "loss": 1.5434,
      "step": 1290
    },
    {
      "epoch": 0.5204163330664532,
      "grad_norm": 0.4430364668369293,
      "learning_rate": 4.1326394448892444e-05,
      "loss": 1.5058,
      "step": 1300
    },
    {
      "epoch": 0.5244195356285029,
      "grad_norm": 0.5624153017997742,
      "learning_rate": 4.1259674406191624e-05,
      "loss": 1.3688,
      "step": 1310
    },
    {
      "epoch": 0.5284227381905524,
      "grad_norm": 0.4459459185600281,
      "learning_rate": 4.119295436349079e-05,
      "loss": 1.5108,
      "step": 1320
    },
    {
      "epoch": 0.5324259407526021,
      "grad_norm": 0.5540438890457153,
      "learning_rate": 4.112623432078997e-05,
      "loss": 1.3928,
      "step": 1330
    },
    {
      "epoch": 0.5364291433146517,
      "grad_norm": 0.5504361391067505,
      "learning_rate": 4.105951427808914e-05,
      "loss": 1.4842,
      "step": 1340
    },
    {
      "epoch": 0.5404323458767014,
      "grad_norm": 0.6025687456130981,
      "learning_rate": 4.099279423538831e-05,
      "loss": 1.5471,
      "step": 1350
    },
    {
      "epoch": 0.544435548438751,
      "grad_norm": 0.3682444393634796,
      "learning_rate": 4.092607419268748e-05,
      "loss": 1.5115,
      "step": 1360
    },
    {
      "epoch": 0.5484387510008006,
      "grad_norm": 0.49797147512435913,
      "learning_rate": 4.0859354149986656e-05,
      "loss": 1.5035,
      "step": 1370
    },
    {
      "epoch": 0.5524419535628503,
      "grad_norm": 0.6869387030601501,
      "learning_rate": 4.079263410728583e-05,
      "loss": 1.3621,
      "step": 1380
    },
    {
      "epoch": 0.5564451561248999,
      "grad_norm": 0.5942458510398865,
      "learning_rate": 4.0725914064585e-05,
      "loss": 1.3834,
      "step": 1390
    },
    {
      "epoch": 0.5604483586869495,
      "grad_norm": 0.44988834857940674,
      "learning_rate": 4.0659194021884176e-05,
      "loss": 1.4855,
      "step": 1400
    },
    {
      "epoch": 0.5644515612489992,
      "grad_norm": 0.3910234570503235,
      "learning_rate": 4.059247397918335e-05,
      "loss": 1.4735,
      "step": 1410
    },
    {
      "epoch": 0.5684547638110489,
      "grad_norm": 0.43886587023735046,
      "learning_rate": 4.052575393648252e-05,
      "loss": 1.4258,
      "step": 1420
    },
    {
      "epoch": 0.5724579663730984,
      "grad_norm": 0.4946357011795044,
      "learning_rate": 4.0459033893781695e-05,
      "loss": 1.5329,
      "step": 1430
    },
    {
      "epoch": 0.5764611689351481,
      "grad_norm": 0.503836989402771,
      "learning_rate": 4.039231385108086e-05,
      "loss": 1.5877,
      "step": 1440
    },
    {
      "epoch": 0.5804643714971978,
      "grad_norm": 0.44500860571861267,
      "learning_rate": 4.032559380838004e-05,
      "loss": 1.5041,
      "step": 1450
    },
    {
      "epoch": 0.5844675740592474,
      "grad_norm": 0.40031376481056213,
      "learning_rate": 4.025887376567921e-05,
      "loss": 1.4522,
      "step": 1460
    },
    {
      "epoch": 0.588470776621297,
      "grad_norm": 0.4090799391269684,
      "learning_rate": 4.019215372297839e-05,
      "loss": 1.3696,
      "step": 1470
    },
    {
      "epoch": 0.5924739791833467,
      "grad_norm": 0.3991433382034302,
      "learning_rate": 4.0125433680277555e-05,
      "loss": 1.5666,
      "step": 1480
    },
    {
      "epoch": 0.5964771817453963,
      "grad_norm": 0.33512479066848755,
      "learning_rate": 4.005871363757673e-05,
      "loss": 1.4509,
      "step": 1490
    },
    {
      "epoch": 0.600480384307446,
      "grad_norm": 0.49056944251060486,
      "learning_rate": 3.99919935948759e-05,
      "loss": 1.3944,
      "step": 1500
    },
    {
      "epoch": 0.6044835868694955,
      "grad_norm": 0.4239122271537781,
      "learning_rate": 3.9925273552175074e-05,
      "loss": 1.4882,
      "step": 1510
    },
    {
      "epoch": 0.6084867894315452,
      "grad_norm": 0.5066034197807312,
      "learning_rate": 3.985855350947425e-05,
      "loss": 1.5017,
      "step": 1520
    },
    {
      "epoch": 0.6124899919935949,
      "grad_norm": 0.49830836057662964,
      "learning_rate": 3.979183346677342e-05,
      "loss": 1.3827,
      "step": 1530
    },
    {
      "epoch": 0.6164931945556446,
      "grad_norm": 0.5366396903991699,
      "learning_rate": 3.9725113424072594e-05,
      "loss": 1.4574,
      "step": 1540
    },
    {
      "epoch": 0.6204963971176941,
      "grad_norm": 0.5250900983810425,
      "learning_rate": 3.965839338137177e-05,
      "loss": 1.4095,
      "step": 1550
    },
    {
      "epoch": 0.6244995996797438,
      "grad_norm": 0.5254610180854797,
      "learning_rate": 3.959167333867094e-05,
      "loss": 1.3342,
      "step": 1560
    },
    {
      "epoch": 0.6285028022417934,
      "grad_norm": 0.5628569722175598,
      "learning_rate": 3.9524953295970113e-05,
      "loss": 1.4428,
      "step": 1570
    },
    {
      "epoch": 0.6325060048038431,
      "grad_norm": 0.5240026712417603,
      "learning_rate": 3.945823325326929e-05,
      "loss": 1.3669,
      "step": 1580
    },
    {
      "epoch": 0.6365092073658927,
      "grad_norm": 0.4104512631893158,
      "learning_rate": 3.939151321056846e-05,
      "loss": 1.4067,
      "step": 1590
    },
    {
      "epoch": 0.6405124099279423,
      "grad_norm": 0.512241780757904,
      "learning_rate": 3.9324793167867626e-05,
      "loss": 1.4671,
      "step": 1600
    },
    {
      "epoch": 0.644515612489992,
      "grad_norm": 0.5095893740653992,
      "learning_rate": 3.92580731251668e-05,
      "loss": 1.571,
      "step": 1610
    },
    {
      "epoch": 0.6485188150520417,
      "grad_norm": 0.6546996831893921,
      "learning_rate": 3.919135308246597e-05,
      "loss": 1.4931,
      "step": 1620
    },
    {
      "epoch": 0.6525220176140912,
      "grad_norm": 0.3566838204860687,
      "learning_rate": 3.9124633039765146e-05,
      "loss": 1.4903,
      "step": 1630
    },
    {
      "epoch": 0.6565252201761409,
      "grad_norm": 0.5528430342674255,
      "learning_rate": 3.905791299706432e-05,
      "loss": 1.4622,
      "step": 1640
    },
    {
      "epoch": 0.6605284227381906,
      "grad_norm": 0.513722836971283,
      "learning_rate": 3.899119295436349e-05,
      "loss": 1.5786,
      "step": 1650
    },
    {
      "epoch": 0.6645316253002402,
      "grad_norm": 0.47387510538101196,
      "learning_rate": 3.8924472911662665e-05,
      "loss": 1.541,
      "step": 1660
    },
    {
      "epoch": 0.6685348278622898,
      "grad_norm": 0.4501666724681854,
      "learning_rate": 3.885775286896184e-05,
      "loss": 1.4509,
      "step": 1670
    },
    {
      "epoch": 0.6725380304243395,
      "grad_norm": 0.4423474669456482,
      "learning_rate": 3.879103282626101e-05,
      "loss": 1.5852,
      "step": 1680
    },
    {
      "epoch": 0.6765412329863891,
      "grad_norm": 0.5408016443252563,
      "learning_rate": 3.8724312783560185e-05,
      "loss": 1.4301,
      "step": 1690
    },
    {
      "epoch": 0.6805444355484388,
      "grad_norm": 0.4196719825267792,
      "learning_rate": 3.865759274085936e-05,
      "loss": 1.5005,
      "step": 1700
    },
    {
      "epoch": 0.6845476381104884,
      "grad_norm": 0.4175063371658325,
      "learning_rate": 3.859087269815853e-05,
      "loss": 1.4347,
      "step": 1710
    },
    {
      "epoch": 0.688550840672538,
      "grad_norm": 0.45168012380599976,
      "learning_rate": 3.8524152655457705e-05,
      "loss": 1.4137,
      "step": 1720
    },
    {
      "epoch": 0.6925540432345877,
      "grad_norm": 0.4565735161304474,
      "learning_rate": 3.845743261275687e-05,
      "loss": 1.5352,
      "step": 1730
    },
    {
      "epoch": 0.6965572457966374,
      "grad_norm": 0.6049816012382507,
      "learning_rate": 3.839071257005605e-05,
      "loss": 1.5841,
      "step": 1740
    },
    {
      "epoch": 0.7005604483586869,
      "grad_norm": 0.6016786098480225,
      "learning_rate": 3.832399252735522e-05,
      "loss": 1.4222,
      "step": 1750
    },
    {
      "epoch": 0.7045636509207366,
      "grad_norm": 0.48717567324638367,
      "learning_rate": 3.825727248465439e-05,
      "loss": 1.4277,
      "step": 1760
    },
    {
      "epoch": 0.7085668534827863,
      "grad_norm": 0.4318484663963318,
      "learning_rate": 3.8190552441953564e-05,
      "loss": 1.4423,
      "step": 1770
    },
    {
      "epoch": 0.7125700560448359,
      "grad_norm": 0.6145709156990051,
      "learning_rate": 3.812383239925274e-05,
      "loss": 1.3755,
      "step": 1780
    },
    {
      "epoch": 0.7165732586068855,
      "grad_norm": 0.5598816275596619,
      "learning_rate": 3.805711235655191e-05,
      "loss": 1.3969,
      "step": 1790
    },
    {
      "epoch": 0.7205764611689351,
      "grad_norm": 0.4427737295627594,
      "learning_rate": 3.7990392313851084e-05,
      "loss": 1.4448,
      "step": 1800
    },
    {
      "epoch": 0.7245796637309848,
      "grad_norm": 0.5692068338394165,
      "learning_rate": 3.792367227115026e-05,
      "loss": 1.5169,
      "step": 1810
    },
    {
      "epoch": 0.7285828662930345,
      "grad_norm": 0.38004815578460693,
      "learning_rate": 3.785695222844943e-05,
      "loss": 1.4538,
      "step": 1820
    },
    {
      "epoch": 0.732586068855084,
      "grad_norm": 0.5015339851379395,
      "learning_rate": 3.77902321857486e-05,
      "loss": 1.4001,
      "step": 1830
    },
    {
      "epoch": 0.7365892714171337,
      "grad_norm": 0.42567142844200134,
      "learning_rate": 3.7723512143047776e-05,
      "loss": 1.6058,
      "step": 1840
    },
    {
      "epoch": 0.7405924739791834,
      "grad_norm": 0.4835817813873291,
      "learning_rate": 3.765679210034694e-05,
      "loss": 1.4691,
      "step": 1850
    },
    {
      "epoch": 0.7445956765412329,
      "grad_norm": 0.49213337898254395,
      "learning_rate": 3.759007205764612e-05,
      "loss": 1.53,
      "step": 1860
    },
    {
      "epoch": 0.7485988791032826,
      "grad_norm": 0.5000189542770386,
      "learning_rate": 3.752335201494529e-05,
      "loss": 1.5419,
      "step": 1870
    },
    {
      "epoch": 0.7526020816653323,
      "grad_norm": 0.4083130955696106,
      "learning_rate": 3.745663197224447e-05,
      "loss": 1.5363,
      "step": 1880
    },
    {
      "epoch": 0.7566052842273819,
      "grad_norm": 0.47156643867492676,
      "learning_rate": 3.7389911929543636e-05,
      "loss": 1.3644,
      "step": 1890
    },
    {
      "epoch": 0.7606084867894315,
      "grad_norm": 0.7229934334754944,
      "learning_rate": 3.732319188684281e-05,
      "loss": 1.4307,
      "step": 1900
    },
    {
      "epoch": 0.7646116893514812,
      "grad_norm": 0.6506049036979675,
      "learning_rate": 3.725647184414198e-05,
      "loss": 1.4279,
      "step": 1910
    },
    {
      "epoch": 0.7686148919135308,
      "grad_norm": 0.3464513123035431,
      "learning_rate": 3.7189751801441155e-05,
      "loss": 1.4735,
      "step": 1920
    },
    {
      "epoch": 0.7726180944755805,
      "grad_norm": 0.4641803205013275,
      "learning_rate": 3.712303175874033e-05,
      "loss": 1.4221,
      "step": 1930
    },
    {
      "epoch": 0.77662129703763,
      "grad_norm": 0.6077064275741577,
      "learning_rate": 3.70563117160395e-05,
      "loss": 1.4819,
      "step": 1940
    },
    {
      "epoch": 0.7806244995996797,
      "grad_norm": 0.38773953914642334,
      "learning_rate": 3.6989591673338675e-05,
      "loss": 1.257,
      "step": 1950
    },
    {
      "epoch": 0.7846277021617294,
      "grad_norm": 0.4575771987438202,
      "learning_rate": 3.692287163063785e-05,
      "loss": 1.448,
      "step": 1960
    },
    {
      "epoch": 0.7886309047237791,
      "grad_norm": 0.5100062489509583,
      "learning_rate": 3.6856151587937014e-05,
      "loss": 1.3857,
      "step": 1970
    },
    {
      "epoch": 0.7926341072858286,
      "grad_norm": 0.6742880344390869,
      "learning_rate": 3.6789431545236194e-05,
      "loss": 1.4916,
      "step": 1980
    },
    {
      "epoch": 0.7966373098478783,
      "grad_norm": 0.45600995421409607,
      "learning_rate": 3.672271150253536e-05,
      "loss": 1.5209,
      "step": 1990
    },
    {
      "epoch": 0.800640512409928,
      "grad_norm": 0.4827800989151001,
      "learning_rate": 3.665599145983454e-05,
      "loss": 1.534,
      "step": 2000
    },
    {
      "epoch": 0.8046437149719776,
      "grad_norm": 0.5135603547096252,
      "learning_rate": 3.658927141713371e-05,
      "loss": 1.5123,
      "step": 2010
    },
    {
      "epoch": 0.8086469175340272,
      "grad_norm": 0.4334707260131836,
      "learning_rate": 3.652255137443289e-05,
      "loss": 1.4765,
      "step": 2020
    },
    {
      "epoch": 0.8126501200960768,
      "grad_norm": 0.4390121102333069,
      "learning_rate": 3.6455831331732054e-05,
      "loss": 1.4195,
      "step": 2030
    },
    {
      "epoch": 0.8166533226581265,
      "grad_norm": 0.4731161594390869,
      "learning_rate": 3.638911128903123e-05,
      "loss": 1.3665,
      "step": 2040
    },
    {
      "epoch": 0.8206565252201762,
      "grad_norm": 0.5426537394523621,
      "learning_rate": 3.63223912463304e-05,
      "loss": 1.374,
      "step": 2050
    },
    {
      "epoch": 0.8246597277822257,
      "grad_norm": 0.5332605838775635,
      "learning_rate": 3.625567120362957e-05,
      "loss": 1.426,
      "step": 2060
    },
    {
      "epoch": 0.8286629303442754,
      "grad_norm": 0.47880250215530396,
      "learning_rate": 3.6188951160928746e-05,
      "loss": 1.3785,
      "step": 2070
    },
    {
      "epoch": 0.8326661329063251,
      "grad_norm": 0.5861021280288696,
      "learning_rate": 3.612223111822792e-05,
      "loss": 1.5156,
      "step": 2080
    },
    {
      "epoch": 0.8366693354683747,
      "grad_norm": 0.5144768953323364,
      "learning_rate": 3.6055511075527086e-05,
      "loss": 1.5229,
      "step": 2090
    },
    {
      "epoch": 0.8406725380304243,
      "grad_norm": 0.4442298412322998,
      "learning_rate": 3.5988791032826266e-05,
      "loss": 1.4035,
      "step": 2100
    },
    {
      "epoch": 0.844675740592474,
      "grad_norm": 0.5242958664894104,
      "learning_rate": 3.592207099012543e-05,
      "loss": 1.491,
      "step": 2110
    },
    {
      "epoch": 0.8486789431545236,
      "grad_norm": 0.47960975766181946,
      "learning_rate": 3.585535094742461e-05,
      "loss": 1.5578,
      "step": 2120
    },
    {
      "epoch": 0.8526821457165733,
      "grad_norm": 0.4884055554866791,
      "learning_rate": 3.578863090472378e-05,
      "loss": 1.4299,
      "step": 2130
    },
    {
      "epoch": 0.8566853482786229,
      "grad_norm": 0.4903477728366852,
      "learning_rate": 3.572191086202296e-05,
      "loss": 1.4152,
      "step": 2140
    },
    {
      "epoch": 0.8606885508406725,
      "grad_norm": 0.47494491934776306,
      "learning_rate": 3.5655190819322125e-05,
      "loss": 1.4685,
      "step": 2150
    },
    {
      "epoch": 0.8646917534027222,
      "grad_norm": 0.6790282726287842,
      "learning_rate": 3.55884707766213e-05,
      "loss": 1.2906,
      "step": 2160
    },
    {
      "epoch": 0.8686949559647719,
      "grad_norm": 0.44809213280677795,
      "learning_rate": 3.552175073392047e-05,
      "loss": 1.3894,
      "step": 2170
    },
    {
      "epoch": 0.8726981585268214,
      "grad_norm": 0.521724283695221,
      "learning_rate": 3.5455030691219645e-05,
      "loss": 1.3359,
      "step": 2180
    },
    {
      "epoch": 0.8767013610888711,
      "grad_norm": 0.4030038118362427,
      "learning_rate": 3.538831064851882e-05,
      "loss": 1.4956,
      "step": 2190
    },
    {
      "epoch": 0.8807045636509208,
      "grad_norm": 0.7157381176948547,
      "learning_rate": 3.532159060581799e-05,
      "loss": 1.4773,
      "step": 2200
    },
    {
      "epoch": 0.8847077662129704,
      "grad_norm": 0.45924651622772217,
      "learning_rate": 3.525487056311716e-05,
      "loss": 1.5223,
      "step": 2210
    },
    {
      "epoch": 0.88871096877502,
      "grad_norm": 0.4412405788898468,
      "learning_rate": 3.518815052041634e-05,
      "loss": 1.4832,
      "step": 2220
    },
    {
      "epoch": 0.8927141713370697,
      "grad_norm": 0.45663467049598694,
      "learning_rate": 3.5121430477715504e-05,
      "loss": 1.4365,
      "step": 2230
    },
    {
      "epoch": 0.8967173738991193,
      "grad_norm": 0.5266395211219788,
      "learning_rate": 3.5054710435014684e-05,
      "loss": 1.5273,
      "step": 2240
    },
    {
      "epoch": 0.900720576461169,
      "grad_norm": 0.3952483534812927,
      "learning_rate": 3.498799039231385e-05,
      "loss": 1.4727,
      "step": 2250
    },
    {
      "epoch": 0.9047237790232185,
      "grad_norm": 0.9706000685691833,
      "learning_rate": 3.492127034961303e-05,
      "loss": 1.4939,
      "step": 2260
    },
    {
      "epoch": 0.9087269815852682,
      "grad_norm": 0.4305795133113861,
      "learning_rate": 3.48545503069122e-05,
      "loss": 1.4228,
      "step": 2270
    },
    {
      "epoch": 0.9127301841473179,
      "grad_norm": 0.45393598079681396,
      "learning_rate": 3.478783026421137e-05,
      "loss": 1.4784,
      "step": 2280
    },
    {
      "epoch": 0.9167333867093675,
      "grad_norm": 0.6832175254821777,
      "learning_rate": 3.472111022151054e-05,
      "loss": 1.3945,
      "step": 2290
    },
    {
      "epoch": 0.9207365892714171,
      "grad_norm": 0.5997034907341003,
      "learning_rate": 3.4654390178809716e-05,
      "loss": 1.3997,
      "step": 2300
    },
    {
      "epoch": 0.9247397918334668,
      "grad_norm": 0.5203831791877747,
      "learning_rate": 3.458767013610889e-05,
      "loss": 1.5263,
      "step": 2310
    },
    {
      "epoch": 0.9287429943955164,
      "grad_norm": 0.3927212357521057,
      "learning_rate": 3.452095009340806e-05,
      "loss": 1.3759,
      "step": 2320
    },
    {
      "epoch": 0.932746196957566,
      "grad_norm": 0.42912614345550537,
      "learning_rate": 3.4454230050707236e-05,
      "loss": 1.5006,
      "step": 2330
    },
    {
      "epoch": 0.9367493995196157,
      "grad_norm": 0.47227415442466736,
      "learning_rate": 3.438751000800641e-05,
      "loss": 1.448,
      "step": 2340
    },
    {
      "epoch": 0.9407526020816653,
      "grad_norm": 0.6653277277946472,
      "learning_rate": 3.4320789965305576e-05,
      "loss": 1.4858,
      "step": 2350
    },
    {
      "epoch": 0.944755804643715,
      "grad_norm": 0.4528685212135315,
      "learning_rate": 3.4254069922604756e-05,
      "loss": 1.5527,
      "step": 2360
    },
    {
      "epoch": 0.9487590072057646,
      "grad_norm": 0.5339608192443848,
      "learning_rate": 3.418734987990392e-05,
      "loss": 1.4495,
      "step": 2370
    },
    {
      "epoch": 0.9527622097678142,
      "grad_norm": 0.498125821352005,
      "learning_rate": 3.41206298372031e-05,
      "loss": 1.4285,
      "step": 2380
    },
    {
      "epoch": 0.9567654123298639,
      "grad_norm": 0.5526306629180908,
      "learning_rate": 3.405390979450227e-05,
      "loss": 1.5,
      "step": 2390
    },
    {
      "epoch": 0.9607686148919136,
      "grad_norm": 0.5708319544792175,
      "learning_rate": 3.398718975180144e-05,
      "loss": 1.4498,
      "step": 2400
    },
    {
      "epoch": 0.9647718174539631,
      "grad_norm": 0.5673840045928955,
      "learning_rate": 3.3920469709100615e-05,
      "loss": 1.4398,
      "step": 2410
    },
    {
      "epoch": 0.9687750200160128,
      "grad_norm": 0.4854029417037964,
      "learning_rate": 3.385374966639979e-05,
      "loss": 1.545,
      "step": 2420
    },
    {
      "epoch": 0.9727782225780625,
      "grad_norm": 0.7254349589347839,
      "learning_rate": 3.378702962369896e-05,
      "loss": 1.4135,
      "step": 2430
    },
    {
      "epoch": 0.9767814251401121,
      "grad_norm": 0.49385127425193787,
      "learning_rate": 3.3720309580998134e-05,
      "loss": 1.465,
      "step": 2440
    },
    {
      "epoch": 0.9807846277021617,
      "grad_norm": 0.4587829113006592,
      "learning_rate": 3.365358953829731e-05,
      "loss": 1.3814,
      "step": 2450
    },
    {
      "epoch": 0.9847878302642114,
      "grad_norm": 0.43143230676651,
      "learning_rate": 3.358686949559648e-05,
      "loss": 1.3237,
      "step": 2460
    },
    {
      "epoch": 0.988791032826261,
      "grad_norm": 0.4662094712257385,
      "learning_rate": 3.352014945289565e-05,
      "loss": 1.4772,
      "step": 2470
    },
    {
      "epoch": 0.9927942353883107,
      "grad_norm": 0.5203567743301392,
      "learning_rate": 3.345342941019483e-05,
      "loss": 1.5605,
      "step": 2480
    },
    {
      "epoch": 0.9967974379503602,
      "grad_norm": 0.4653262495994568,
      "learning_rate": 3.3386709367493994e-05,
      "loss": 1.3711,
      "step": 2490
    },
    {
      "epoch": 1.00080064051241,
      "grad_norm": 0.4649437665939331,
      "learning_rate": 3.3319989324793174e-05,
      "loss": 1.4232,
      "step": 2500
    },
    {
      "epoch": 1.0048038430744595,
      "grad_norm": 0.4819064140319824,
      "learning_rate": 3.325326928209234e-05,
      "loss": 1.4762,
      "step": 2510
    },
    {
      "epoch": 1.0088070456365092,
      "grad_norm": 0.45263105630874634,
      "learning_rate": 3.318654923939151e-05,
      "loss": 1.5812,
      "step": 2520
    },
    {
      "epoch": 1.0128102481985588,
      "grad_norm": 0.6049274802207947,
      "learning_rate": 3.3119829196690686e-05,
      "loss": 1.4342,
      "step": 2530
    },
    {
      "epoch": 1.0168134507606086,
      "grad_norm": 0.570626974105835,
      "learning_rate": 3.305310915398986e-05,
      "loss": 1.3835,
      "step": 2540
    },
    {
      "epoch": 1.0208166533226581,
      "grad_norm": 0.4357350170612335,
      "learning_rate": 3.298638911128903e-05,
      "loss": 1.4891,
      "step": 2550
    },
    {
      "epoch": 1.0248198558847077,
      "grad_norm": 0.48652172088623047,
      "learning_rate": 3.2919669068588206e-05,
      "loss": 1.4132,
      "step": 2560
    },
    {
      "epoch": 1.0288230584467575,
      "grad_norm": 0.44666486978530884,
      "learning_rate": 3.285294902588738e-05,
      "loss": 1.4456,
      "step": 2570
    },
    {
      "epoch": 1.032826261008807,
      "grad_norm": 0.44364386796951294,
      "learning_rate": 3.278622898318655e-05,
      "loss": 1.3682,
      "step": 2580
    },
    {
      "epoch": 1.0368294635708566,
      "grad_norm": 0.7200059294700623,
      "learning_rate": 3.271950894048572e-05,
      "loss": 1.4514,
      "step": 2590
    },
    {
      "epoch": 1.0408326661329064,
      "grad_norm": 0.4392048418521881,
      "learning_rate": 3.26527888977849e-05,
      "loss": 1.4034,
      "step": 2600
    },
    {
      "epoch": 1.044835868694956,
      "grad_norm": 0.5073825716972351,
      "learning_rate": 3.2586068855084065e-05,
      "loss": 1.4419,
      "step": 2610
    },
    {
      "epoch": 1.0488390712570057,
      "grad_norm": 0.508743166923523,
      "learning_rate": 3.2519348812383245e-05,
      "loss": 1.4559,
      "step": 2620
    },
    {
      "epoch": 1.0528422738190553,
      "grad_norm": 0.40567460656166077,
      "learning_rate": 3.245262876968241e-05,
      "loss": 1.4084,
      "step": 2630
    },
    {
      "epoch": 1.0568454763811048,
      "grad_norm": 0.4800167679786682,
      "learning_rate": 3.2385908726981585e-05,
      "loss": 1.5878,
      "step": 2640
    },
    {
      "epoch": 1.0608486789431546,
      "grad_norm": 0.4712342321872711,
      "learning_rate": 3.231918868428076e-05,
      "loss": 1.4443,
      "step": 2650
    },
    {
      "epoch": 1.0648518815052042,
      "grad_norm": 0.5267324447631836,
      "learning_rate": 3.225246864157993e-05,
      "loss": 1.4396,
      "step": 2660
    },
    {
      "epoch": 1.0688550840672537,
      "grad_norm": 0.47881031036376953,
      "learning_rate": 3.2185748598879104e-05,
      "loss": 1.4018,
      "step": 2670
    },
    {
      "epoch": 1.0728582866293035,
      "grad_norm": 0.4940982758998871,
      "learning_rate": 3.211902855617828e-05,
      "loss": 1.582,
      "step": 2680
    },
    {
      "epoch": 1.076861489191353,
      "grad_norm": 0.4768792986869812,
      "learning_rate": 3.205230851347745e-05,
      "loss": 1.518,
      "step": 2690
    },
    {
      "epoch": 1.0808646917534026,
      "grad_norm": 0.5432795882225037,
      "learning_rate": 3.1985588470776624e-05,
      "loss": 1.3262,
      "step": 2700
    },
    {
      "epoch": 1.0848678943154524,
      "grad_norm": 0.480604350566864,
      "learning_rate": 3.191886842807579e-05,
      "loss": 1.4176,
      "step": 2710
    },
    {
      "epoch": 1.088871096877502,
      "grad_norm": 0.5365002155303955,
      "learning_rate": 3.185214838537497e-05,
      "loss": 1.3941,
      "step": 2720
    },
    {
      "epoch": 1.0928742994395517,
      "grad_norm": 0.5818739533424377,
      "learning_rate": 3.178542834267414e-05,
      "loss": 1.4899,
      "step": 2730
    },
    {
      "epoch": 1.0968775020016013,
      "grad_norm": 0.5346069931983948,
      "learning_rate": 3.171870829997332e-05,
      "loss": 1.3181,
      "step": 2740
    },
    {
      "epoch": 1.1008807045636508,
      "grad_norm": 0.4653657078742981,
      "learning_rate": 3.165198825727248e-05,
      "loss": 1.4882,
      "step": 2750
    },
    {
      "epoch": 1.1048839071257006,
      "grad_norm": 0.47198960185050964,
      "learning_rate": 3.1585268214571657e-05,
      "loss": 1.5659,
      "step": 2760
    },
    {
      "epoch": 1.1088871096877502,
      "grad_norm": 0.611986517906189,
      "learning_rate": 3.151854817187083e-05,
      "loss": 1.5608,
      "step": 2770
    },
    {
      "epoch": 1.1128903122498,
      "grad_norm": 0.45744043588638306,
      "learning_rate": 3.145182812917e-05,
      "loss": 1.4724,
      "step": 2780
    },
    {
      "epoch": 1.1168935148118495,
      "grad_norm": 0.45784661173820496,
      "learning_rate": 3.1385108086469176e-05,
      "loss": 1.5254,
      "step": 2790
    },
    {
      "epoch": 1.120896717373899,
      "grad_norm": 0.49358174204826355,
      "learning_rate": 3.131838804376835e-05,
      "loss": 1.4035,
      "step": 2800
    },
    {
      "epoch": 1.1248999199359488,
      "grad_norm": 0.5372592210769653,
      "learning_rate": 3.125166800106752e-05,
      "loss": 1.4043,
      "step": 2810
    },
    {
      "epoch": 1.1289031224979984,
      "grad_norm": 0.5018174052238464,
      "learning_rate": 3.1184947958366696e-05,
      "loss": 1.4739,
      "step": 2820
    },
    {
      "epoch": 1.132906325060048,
      "grad_norm": 0.628913938999176,
      "learning_rate": 3.111822791566586e-05,
      "loss": 1.4098,
      "step": 2830
    },
    {
      "epoch": 1.1369095276220977,
      "grad_norm": 0.47084468603134155,
      "learning_rate": 3.105150787296504e-05,
      "loss": 1.4628,
      "step": 2840
    },
    {
      "epoch": 1.1409127301841473,
      "grad_norm": 0.4866783022880554,
      "learning_rate": 3.098478783026421e-05,
      "loss": 1.4329,
      "step": 2850
    },
    {
      "epoch": 1.1449159327461969,
      "grad_norm": 0.667360246181488,
      "learning_rate": 3.091806778756339e-05,
      "loss": 1.4806,
      "step": 2860
    },
    {
      "epoch": 1.1489191353082466,
      "grad_norm": 0.48443910479545593,
      "learning_rate": 3.0851347744862555e-05,
      "loss": 1.4672,
      "step": 2870
    },
    {
      "epoch": 1.1529223378702962,
      "grad_norm": 0.5321230292320251,
      "learning_rate": 3.0784627702161735e-05,
      "loss": 1.4238,
      "step": 2880
    },
    {
      "epoch": 1.156925540432346,
      "grad_norm": 0.49697211384773254,
      "learning_rate": 3.07179076594609e-05,
      "loss": 1.4361,
      "step": 2890
    },
    {
      "epoch": 1.1609287429943955,
      "grad_norm": 1.231376051902771,
      "learning_rate": 3.0651187616760075e-05,
      "loss": 1.3103,
      "step": 2900
    },
    {
      "epoch": 1.164931945556445,
      "grad_norm": 0.4068288207054138,
      "learning_rate": 3.058446757405925e-05,
      "loss": 1.3707,
      "step": 2910
    },
    {
      "epoch": 1.1689351481184949,
      "grad_norm": 0.551660418510437,
      "learning_rate": 3.051774753135842e-05,
      "loss": 1.3231,
      "step": 2920
    },
    {
      "epoch": 1.1729383506805444,
      "grad_norm": 0.46793362498283386,
      "learning_rate": 3.0451027488657598e-05,
      "loss": 1.419,
      "step": 2930
    },
    {
      "epoch": 1.1769415532425942,
      "grad_norm": 0.393889456987381,
      "learning_rate": 3.0384307445956767e-05,
      "loss": 1.4439,
      "step": 2940
    },
    {
      "epoch": 1.1809447558046438,
      "grad_norm": 0.4399191737174988,
      "learning_rate": 3.0317587403255937e-05,
      "loss": 1.4088,
      "step": 2950
    },
    {
      "epoch": 1.1849479583666933,
      "grad_norm": 0.49565115571022034,
      "learning_rate": 3.0250867360555114e-05,
      "loss": 1.4264,
      "step": 2960
    },
    {
      "epoch": 1.188951160928743,
      "grad_norm": 0.5638555288314819,
      "learning_rate": 3.0184147317854284e-05,
      "loss": 1.4684,
      "step": 2970
    },
    {
      "epoch": 1.1929543634907926,
      "grad_norm": 0.4346698224544525,
      "learning_rate": 3.011742727515346e-05,
      "loss": 1.3845,
      "step": 2980
    },
    {
      "epoch": 1.1969575660528422,
      "grad_norm": 0.5223327279090881,
      "learning_rate": 3.005070723245263e-05,
      "loss": 1.4396,
      "step": 2990
    },
    {
      "epoch": 1.200960768614892,
      "grad_norm": 0.47960758209228516,
      "learning_rate": 2.9983987189751807e-05,
      "loss": 1.438,
      "step": 3000
    },
    {
      "epoch": 1.2049639711769415,
      "grad_norm": 0.45177212357521057,
      "learning_rate": 2.9917267147050976e-05,
      "loss": 1.4583,
      "step": 3010
    },
    {
      "epoch": 1.208967173738991,
      "grad_norm": 0.4782741665840149,
      "learning_rate": 2.9850547104350146e-05,
      "loss": 1.3839,
      "step": 3020
    },
    {
      "epoch": 1.2129703763010409,
      "grad_norm": 0.5602673292160034,
      "learning_rate": 2.9783827061649323e-05,
      "loss": 1.3849,
      "step": 3030
    },
    {
      "epoch": 1.2169735788630904,
      "grad_norm": 0.5085766315460205,
      "learning_rate": 2.9717107018948493e-05,
      "loss": 1.3023,
      "step": 3040
    },
    {
      "epoch": 1.22097678142514,
      "grad_norm": 0.49862006306648254,
      "learning_rate": 2.965038697624767e-05,
      "loss": 1.4114,
      "step": 3050
    },
    {
      "epoch": 1.2249799839871898,
      "grad_norm": 0.5358912348747253,
      "learning_rate": 2.958366693354684e-05,
      "loss": 1.3767,
      "step": 3060
    },
    {
      "epoch": 1.2289831865492393,
      "grad_norm": 0.5091111063957214,
      "learning_rate": 2.951694689084601e-05,
      "loss": 1.4752,
      "step": 3070
    },
    {
      "epoch": 1.232986389111289,
      "grad_norm": 0.4350118935108185,
      "learning_rate": 2.9450226848145185e-05,
      "loss": 1.3469,
      "step": 3080
    },
    {
      "epoch": 1.2369895916733387,
      "grad_norm": 0.5041558146476746,
      "learning_rate": 2.9383506805444355e-05,
      "loss": 1.3445,
      "step": 3090
    },
    {
      "epoch": 1.2409927942353882,
      "grad_norm": 0.41618525981903076,
      "learning_rate": 2.9316786762743532e-05,
      "loss": 1.375,
      "step": 3100
    },
    {
      "epoch": 1.244995996797438,
      "grad_norm": 0.48896780610084534,
      "learning_rate": 2.92500667200427e-05,
      "loss": 1.3234,
      "step": 3110
    },
    {
      "epoch": 1.2489991993594876,
      "grad_norm": 0.5094597339630127,
      "learning_rate": 2.9183346677341878e-05,
      "loss": 1.3524,
      "step": 3120
    },
    {
      "epoch": 1.2530024019215373,
      "grad_norm": 0.5408208966255188,
      "learning_rate": 2.9116626634641048e-05,
      "loss": 1.373,
      "step": 3130
    },
    {
      "epoch": 1.257005604483587,
      "grad_norm": 0.6537120938301086,
      "learning_rate": 2.9049906591940218e-05,
      "loss": 1.4263,
      "step": 3140
    },
    {
      "epoch": 1.2610088070456364,
      "grad_norm": 3.1619679927825928,
      "learning_rate": 2.8983186549239394e-05,
      "loss": 1.4154,
      "step": 3150
    },
    {
      "epoch": 1.2650120096076862,
      "grad_norm": 0.5703919529914856,
      "learning_rate": 2.8916466506538564e-05,
      "loss": 1.4337,
      "step": 3160
    },
    {
      "epoch": 1.2690152121697358,
      "grad_norm": 0.5120583176612854,
      "learning_rate": 2.884974646383774e-05,
      "loss": 1.3846,
      "step": 3170
    },
    {
      "epoch": 1.2730184147317853,
      "grad_norm": 0.48045551776885986,
      "learning_rate": 2.878302642113691e-05,
      "loss": 1.4126,
      "step": 3180
    },
    {
      "epoch": 1.2770216172938351,
      "grad_norm": 0.43504709005355835,
      "learning_rate": 2.871630637843608e-05,
      "loss": 1.2881,
      "step": 3190
    },
    {
      "epoch": 1.2810248198558847,
      "grad_norm": 0.5450352430343628,
      "learning_rate": 2.8649586335735257e-05,
      "loss": 1.332,
      "step": 3200
    },
    {
      "epoch": 1.2850280224179342,
      "grad_norm": 0.40494999289512634,
      "learning_rate": 2.8582866293034427e-05,
      "loss": 1.3392,
      "step": 3210
    },
    {
      "epoch": 1.289031224979984,
      "grad_norm": 0.542921781539917,
      "learning_rate": 2.8516146250333603e-05,
      "loss": 1.4624,
      "step": 3220
    },
    {
      "epoch": 1.2930344275420336,
      "grad_norm": 0.42991724610328674,
      "learning_rate": 2.8449426207632773e-05,
      "loss": 1.4649,
      "step": 3230
    },
    {
      "epoch": 1.2970376301040831,
      "grad_norm": 0.48841407895088196,
      "learning_rate": 2.838270616493195e-05,
      "loss": 1.4071,
      "step": 3240
    },
    {
      "epoch": 1.301040832666133,
      "grad_norm": 0.4141535460948944,
      "learning_rate": 2.831598612223112e-05,
      "loss": 1.4696,
      "step": 3250
    },
    {
      "epoch": 1.3050440352281825,
      "grad_norm": 0.427910178899765,
      "learning_rate": 2.824926607953029e-05,
      "loss": 1.4797,
      "step": 3260
    },
    {
      "epoch": 1.3090472377902322,
      "grad_norm": 0.5367609262466431,
      "learning_rate": 2.8182546036829466e-05,
      "loss": 1.4354,
      "step": 3270
    },
    {
      "epoch": 1.3130504403522818,
      "grad_norm": 0.42366063594818115,
      "learning_rate": 2.8115825994128636e-05,
      "loss": 1.4427,
      "step": 3280
    },
    {
      "epoch": 1.3170536429143316,
      "grad_norm": 0.6505997776985168,
      "learning_rate": 2.8049105951427812e-05,
      "loss": 1.4305,
      "step": 3290
    },
    {
      "epoch": 1.3210568454763811,
      "grad_norm": 0.5100040435791016,
      "learning_rate": 2.7982385908726982e-05,
      "loss": 1.3296,
      "step": 3300
    },
    {
      "epoch": 1.3250600480384307,
      "grad_norm": 0.5598462224006653,
      "learning_rate": 2.791566586602616e-05,
      "loss": 1.4612,
      "step": 3310
    },
    {
      "epoch": 1.3290632506004805,
      "grad_norm": 0.5478867292404175,
      "learning_rate": 2.784894582332533e-05,
      "loss": 1.3598,
      "step": 3320
    },
    {
      "epoch": 1.33306645316253,
      "grad_norm": 0.49971070885658264,
      "learning_rate": 2.77822257806245e-05,
      "loss": 1.4681,
      "step": 3330
    },
    {
      "epoch": 1.3370696557245796,
      "grad_norm": 0.4793206751346588,
      "learning_rate": 2.7715505737923675e-05,
      "loss": 1.4878,
      "step": 3340
    },
    {
      "epoch": 1.3410728582866294,
      "grad_norm": 0.49358871579170227,
      "learning_rate": 2.7648785695222845e-05,
      "loss": 1.3635,
      "step": 3350
    },
    {
      "epoch": 1.345076060848679,
      "grad_norm": 0.5166341662406921,
      "learning_rate": 2.758206565252202e-05,
      "loss": 1.447,
      "step": 3360
    },
    {
      "epoch": 1.3490792634107285,
      "grad_norm": 0.5114778280258179,
      "learning_rate": 2.751534560982119e-05,
      "loss": 1.5259,
      "step": 3370
    },
    {
      "epoch": 1.3530824659727783,
      "grad_norm": 0.5280218720436096,
      "learning_rate": 2.744862556712036e-05,
      "loss": 1.4001,
      "step": 3380
    },
    {
      "epoch": 1.3570856685348278,
      "grad_norm": 0.42716044187545776,
      "learning_rate": 2.7381905524419538e-05,
      "loss": 1.5061,
      "step": 3390
    },
    {
      "epoch": 1.3610888710968774,
      "grad_norm": 0.49654918909072876,
      "learning_rate": 2.7315185481718707e-05,
      "loss": 1.4064,
      "step": 3400
    },
    {
      "epoch": 1.3650920736589272,
      "grad_norm": 0.5916392803192139,
      "learning_rate": 2.7248465439017884e-05,
      "loss": 1.331,
      "step": 3410
    },
    {
      "epoch": 1.3690952762209767,
      "grad_norm": 0.5847174525260925,
      "learning_rate": 2.7181745396317054e-05,
      "loss": 1.4455,
      "step": 3420
    },
    {
      "epoch": 1.3730984787830265,
      "grad_norm": 0.4861277937889099,
      "learning_rate": 2.711502535361623e-05,
      "loss": 1.48,
      "step": 3430
    },
    {
      "epoch": 1.377101681345076,
      "grad_norm": 0.435592383146286,
      "learning_rate": 2.70483053109154e-05,
      "loss": 1.4562,
      "step": 3440
    },
    {
      "epoch": 1.3811048839071258,
      "grad_norm": 0.5646371841430664,
      "learning_rate": 2.698158526821457e-05,
      "loss": 1.313,
      "step": 3450
    },
    {
      "epoch": 1.3851080864691754,
      "grad_norm": 0.5115575194358826,
      "learning_rate": 2.6914865225513747e-05,
      "loss": 1.4439,
      "step": 3460
    },
    {
      "epoch": 1.389111289031225,
      "grad_norm": 0.5336971879005432,
      "learning_rate": 2.6848145182812916e-05,
      "loss": 1.4369,
      "step": 3470
    },
    {
      "epoch": 1.3931144915932747,
      "grad_norm": 0.4837424159049988,
      "learning_rate": 2.6781425140112093e-05,
      "loss": 1.3311,
      "step": 3480
    },
    {
      "epoch": 1.3971176941553243,
      "grad_norm": 0.490019828081131,
      "learning_rate": 2.6714705097411263e-05,
      "loss": 1.4758,
      "step": 3490
    },
    {
      "epoch": 1.4011208967173738,
      "grad_norm": 0.7517901062965393,
      "learning_rate": 2.6647985054710433e-05,
      "loss": 1.4159,
      "step": 3500
    },
    {
      "epoch": 1.4051240992794236,
      "grad_norm": 0.45867398381233215,
      "learning_rate": 2.658126501200961e-05,
      "loss": 1.4916,
      "step": 3510
    },
    {
      "epoch": 1.4091273018414732,
      "grad_norm": 0.5144290924072266,
      "learning_rate": 2.651454496930878e-05,
      "loss": 1.4882,
      "step": 3520
    },
    {
      "epoch": 1.4131305044035227,
      "grad_norm": 0.5806825160980225,
      "learning_rate": 2.6447824926607956e-05,
      "loss": 1.3497,
      "step": 3530
    },
    {
      "epoch": 1.4171337069655725,
      "grad_norm": 0.5912393927574158,
      "learning_rate": 2.6381104883907125e-05,
      "loss": 1.4137,
      "step": 3540
    },
    {
      "epoch": 1.421136909527622,
      "grad_norm": 0.4566034972667694,
      "learning_rate": 2.6314384841206302e-05,
      "loss": 1.4003,
      "step": 3550
    },
    {
      "epoch": 1.4251401120896716,
      "grad_norm": 0.4432600736618042,
      "learning_rate": 2.6247664798505472e-05,
      "loss": 1.425,
      "step": 3560
    },
    {
      "epoch": 1.4291433146517214,
      "grad_norm": 0.4722660779953003,
      "learning_rate": 2.618094475580464e-05,
      "loss": 1.3486,
      "step": 3570
    },
    {
      "epoch": 1.433146517213771,
      "grad_norm": 0.42887812852859497,
      "learning_rate": 2.6114224713103818e-05,
      "loss": 1.4571,
      "step": 3580
    },
    {
      "epoch": 1.4371497197758207,
      "grad_norm": 0.4700014591217041,
      "learning_rate": 2.6047504670402988e-05,
      "loss": 1.3642,
      "step": 3590
    },
    {
      "epoch": 1.4411529223378703,
      "grad_norm": 0.4411672353744507,
      "learning_rate": 2.5980784627702165e-05,
      "loss": 1.4968,
      "step": 3600
    },
    {
      "epoch": 1.44515612489992,
      "grad_norm": 0.5673602819442749,
      "learning_rate": 2.5914064585001334e-05,
      "loss": 1.4071,
      "step": 3610
    },
    {
      "epoch": 1.4491593274619696,
      "grad_norm": 0.4881351888179779,
      "learning_rate": 2.5847344542300504e-05,
      "loss": 1.4218,
      "step": 3620
    },
    {
      "epoch": 1.4531625300240192,
      "grad_norm": 0.5535302758216858,
      "learning_rate": 2.578062449959968e-05,
      "loss": 1.4266,
      "step": 3630
    },
    {
      "epoch": 1.457165732586069,
      "grad_norm": 0.47246432304382324,
      "learning_rate": 2.571390445689885e-05,
      "loss": 1.486,
      "step": 3640
    },
    {
      "epoch": 1.4611689351481185,
      "grad_norm": 0.4639769494533539,
      "learning_rate": 2.5647184414198027e-05,
      "loss": 1.3687,
      "step": 3650
    },
    {
      "epoch": 1.465172137710168,
      "grad_norm": 0.5319058895111084,
      "learning_rate": 2.5580464371497197e-05,
      "loss": 1.424,
      "step": 3660
    },
    {
      "epoch": 1.4691753402722179,
      "grad_norm": 0.4942071735858917,
      "learning_rate": 2.5513744328796374e-05,
      "loss": 1.381,
      "step": 3670
    },
    {
      "epoch": 1.4731785428342674,
      "grad_norm": 0.4100518822669983,
      "learning_rate": 2.5447024286095543e-05,
      "loss": 1.5853,
      "step": 3680
    },
    {
      "epoch": 1.477181745396317,
      "grad_norm": 0.6136505603790283,
      "learning_rate": 2.5380304243394713e-05,
      "loss": 1.4461,
      "step": 3690
    },
    {
      "epoch": 1.4811849479583667,
      "grad_norm": 0.635127604007721,
      "learning_rate": 2.531358420069389e-05,
      "loss": 1.4718,
      "step": 3700
    },
    {
      "epoch": 1.4851881505204163,
      "grad_norm": 0.44812679290771484,
      "learning_rate": 2.524686415799306e-05,
      "loss": 1.3897,
      "step": 3710
    },
    {
      "epoch": 1.4891913530824659,
      "grad_norm": 0.44199156761169434,
      "learning_rate": 2.5180144115292236e-05,
      "loss": 1.4869,
      "step": 3720
    },
    {
      "epoch": 1.4931945556445156,
      "grad_norm": 0.6489483118057251,
      "learning_rate": 2.5113424072591406e-05,
      "loss": 1.3667,
      "step": 3730
    },
    {
      "epoch": 1.4971977582065652,
      "grad_norm": 0.4710582494735718,
      "learning_rate": 2.5046704029890583e-05,
      "loss": 1.4776,
      "step": 3740
    },
    {
      "epoch": 1.5012009607686148,
      "grad_norm": 0.43117913603782654,
      "learning_rate": 2.4979983987189752e-05,
      "loss": 1.3985,
      "step": 3750
    },
    {
      "epoch": 1.5052041633306645,
      "grad_norm": 0.44761407375335693,
      "learning_rate": 2.4913263944488926e-05,
      "loss": 1.3683,
      "step": 3760
    },
    {
      "epoch": 1.5092073658927143,
      "grad_norm": 0.478639155626297,
      "learning_rate": 2.48465439017881e-05,
      "loss": 1.4865,
      "step": 3770
    },
    {
      "epoch": 1.5132105684547636,
      "grad_norm": 0.5065186023712158,
      "learning_rate": 2.477982385908727e-05,
      "loss": 1.4116,
      "step": 3780
    },
    {
      "epoch": 1.5172137710168134,
      "grad_norm": 0.4603687822818756,
      "learning_rate": 2.4713103816386442e-05,
      "loss": 1.3492,
      "step": 3790
    },
    {
      "epoch": 1.5212169735788632,
      "grad_norm": 0.4884987473487854,
      "learning_rate": 2.4646383773685615e-05,
      "loss": 1.373,
      "step": 3800
    },
    {
      "epoch": 1.5252201761409128,
      "grad_norm": 0.46699634194374084,
      "learning_rate": 2.4579663730984788e-05,
      "loss": 1.401,
      "step": 3810
    },
    {
      "epoch": 1.5292233787029623,
      "grad_norm": 0.48611414432525635,
      "learning_rate": 2.451294368828396e-05,
      "loss": 1.5527,
      "step": 3820
    },
    {
      "epoch": 1.533226581265012,
      "grad_norm": 0.5229470133781433,
      "learning_rate": 2.4446223645583135e-05,
      "loss": 1.429,
      "step": 3830
    },
    {
      "epoch": 1.5372297838270617,
      "grad_norm": 0.4736758768558502,
      "learning_rate": 2.4379503602882305e-05,
      "loss": 1.4628,
      "step": 3840
    },
    {
      "epoch": 1.5412329863891112,
      "grad_norm": 0.4605308473110199,
      "learning_rate": 2.4312783560181478e-05,
      "loss": 1.358,
      "step": 3850
    },
    {
      "epoch": 1.545236188951161,
      "grad_norm": 0.46054014563560486,
      "learning_rate": 2.424606351748065e-05,
      "loss": 1.3162,
      "step": 3860
    },
    {
      "epoch": 1.5492393915132106,
      "grad_norm": 0.5425366163253784,
      "learning_rate": 2.4179343474779824e-05,
      "loss": 1.4495,
      "step": 3870
    },
    {
      "epoch": 1.55324259407526,
      "grad_norm": 0.5807620286941528,
      "learning_rate": 2.4112623432078997e-05,
      "loss": 1.4948,
      "step": 3880
    },
    {
      "epoch": 1.5572457966373099,
      "grad_norm": 0.4330389201641083,
      "learning_rate": 2.404590338937817e-05,
      "loss": 1.3509,
      "step": 3890
    },
    {
      "epoch": 1.5612489991993594,
      "grad_norm": 0.5650457143783569,
      "learning_rate": 2.397918334667734e-05,
      "loss": 1.4999,
      "step": 3900
    },
    {
      "epoch": 1.565252201761409,
      "grad_norm": 0.473876029253006,
      "learning_rate": 2.3912463303976514e-05,
      "loss": 1.4231,
      "step": 3910
    },
    {
      "epoch": 1.5692554043234588,
      "grad_norm": 0.5370983481407166,
      "learning_rate": 2.3845743261275687e-05,
      "loss": 1.2701,
      "step": 3920
    },
    {
      "epoch": 1.5732586068855086,
      "grad_norm": 0.47117653489112854,
      "learning_rate": 2.377902321857486e-05,
      "loss": 1.3445,
      "step": 3930
    },
    {
      "epoch": 1.577261809447558,
      "grad_norm": 0.5145094394683838,
      "learning_rate": 2.3712303175874033e-05,
      "loss": 1.3994,
      "step": 3940
    },
    {
      "epoch": 1.5812650120096077,
      "grad_norm": 0.43601977825164795,
      "learning_rate": 2.3645583133173206e-05,
      "loss": 1.3877,
      "step": 3950
    },
    {
      "epoch": 1.5852682145716575,
      "grad_norm": 0.5870351791381836,
      "learning_rate": 2.357886309047238e-05,
      "loss": 1.38,
      "step": 3960
    },
    {
      "epoch": 1.589271417133707,
      "grad_norm": 0.5473050475120544,
      "learning_rate": 2.351214304777155e-05,
      "loss": 1.4356,
      "step": 3970
    },
    {
      "epoch": 1.5932746196957566,
      "grad_norm": 0.4652182459831238,
      "learning_rate": 2.3445423005070723e-05,
      "loss": 1.3975,
      "step": 3980
    },
    {
      "epoch": 1.5972778222578063,
      "grad_norm": 0.5174634456634521,
      "learning_rate": 2.3378702962369896e-05,
      "loss": 1.334,
      "step": 3990
    },
    {
      "epoch": 1.601281024819856,
      "grad_norm": 0.5450606346130371,
      "learning_rate": 2.331198291966907e-05,
      "loss": 1.2855,
      "step": 4000
    },
    {
      "epoch": 1.6052842273819055,
      "grad_norm": 0.48155131936073303,
      "learning_rate": 2.3245262876968242e-05,
      "loss": 1.4172,
      "step": 4010
    },
    {
      "epoch": 1.6092874299439552,
      "grad_norm": 0.5398070216178894,
      "learning_rate": 2.3178542834267415e-05,
      "loss": 1.4788,
      "step": 4020
    },
    {
      "epoch": 1.6132906325060048,
      "grad_norm": 0.5427486300468445,
      "learning_rate": 2.311182279156659e-05,
      "loss": 1.5055,
      "step": 4030
    },
    {
      "epoch": 1.6172938350680544,
      "grad_norm": 0.4849322736263275,
      "learning_rate": 2.3045102748865762e-05,
      "loss": 1.3739,
      "step": 4040
    },
    {
      "epoch": 1.6212970376301041,
      "grad_norm": 0.5811575055122375,
      "learning_rate": 2.297838270616493e-05,
      "loss": 1.5404,
      "step": 4050
    },
    {
      "epoch": 1.6253002401921537,
      "grad_norm": 0.5333170294761658,
      "learning_rate": 2.2911662663464105e-05,
      "loss": 1.2791,
      "step": 4060
    },
    {
      "epoch": 1.6293034427542032,
      "grad_norm": 0.5918942093849182,
      "learning_rate": 2.2844942620763278e-05,
      "loss": 1.4539,
      "step": 4070
    },
    {
      "epoch": 1.633306645316253,
      "grad_norm": 0.4478846788406372,
      "learning_rate": 2.277822257806245e-05,
      "loss": 1.3734,
      "step": 4080
    },
    {
      "epoch": 1.6373098478783028,
      "grad_norm": 0.5065019726753235,
      "learning_rate": 2.2711502535361624e-05,
      "loss": 1.3531,
      "step": 4090
    },
    {
      "epoch": 1.6413130504403521,
      "grad_norm": 0.4653777778148651,
      "learning_rate": 2.2644782492660798e-05,
      "loss": 1.4645,
      "step": 4100
    },
    {
      "epoch": 1.645316253002402,
      "grad_norm": 0.520879864692688,
      "learning_rate": 2.258473445423005e-05,
      "loss": 1.4325,
      "step": 4110
    },
    {
      "epoch": 1.6493194555644517,
      "grad_norm": 0.49428948760032654,
      "learning_rate": 2.2518014411529225e-05,
      "loss": 1.4903,
      "step": 4120
    },
    {
      "epoch": 1.6533226581265013,
      "grad_norm": 0.48515281081199646,
      "learning_rate": 2.2451294368828398e-05,
      "loss": 1.4785,
      "step": 4130
    },
    {
      "epoch": 1.6573258606885508,
      "grad_norm": 0.7584293484687805,
      "learning_rate": 2.2384574326127568e-05,
      "loss": 1.4927,
      "step": 4140
    },
    {
      "epoch": 1.6613290632506006,
      "grad_norm": 0.6180858612060547,
      "learning_rate": 2.231785428342674e-05,
      "loss": 1.4913,
      "step": 4150
    },
    {
      "epoch": 1.6653322658126501,
      "grad_norm": 0.4964556396007538,
      "learning_rate": 2.2251134240725914e-05,
      "loss": 1.48,
      "step": 4160
    },
    {
      "epoch": 1.6693354683746997,
      "grad_norm": 0.6559728384017944,
      "learning_rate": 2.2184414198025087e-05,
      "loss": 1.333,
      "step": 4170
    },
    {
      "epoch": 1.6733386709367495,
      "grad_norm": 0.434352844953537,
      "learning_rate": 2.211769415532426e-05,
      "loss": 1.2738,
      "step": 4180
    },
    {
      "epoch": 1.677341873498799,
      "grad_norm": 0.4554382264614105,
      "learning_rate": 2.2050974112623434e-05,
      "loss": 1.5013,
      "step": 4190
    },
    {
      "epoch": 1.6813450760608486,
      "grad_norm": 0.5204465985298157,
      "learning_rate": 2.1984254069922607e-05,
      "loss": 1.4765,
      "step": 4200
    },
    {
      "epoch": 1.6853482786228984,
      "grad_norm": 0.5940012335777283,
      "learning_rate": 2.1917534027221777e-05,
      "loss": 1.3732,
      "step": 4210
    },
    {
      "epoch": 1.689351481184948,
      "grad_norm": 0.5792732238769531,
      "learning_rate": 2.185081398452095e-05,
      "loss": 1.3806,
      "step": 4220
    },
    {
      "epoch": 1.6933546837469975,
      "grad_norm": 0.8228227496147156,
      "learning_rate": 2.1784093941820123e-05,
      "loss": 1.3901,
      "step": 4230
    },
    {
      "epoch": 1.6973578863090473,
      "grad_norm": 0.4654918611049652,
      "learning_rate": 2.1717373899119296e-05,
      "loss": 1.3621,
      "step": 4240
    },
    {
      "epoch": 1.7013610888710968,
      "grad_norm": 0.4861034154891968,
      "learning_rate": 2.165065385641847e-05,
      "loss": 1.3244,
      "step": 4250
    },
    {
      "epoch": 1.7053642914331464,
      "grad_norm": 0.41429996490478516,
      "learning_rate": 2.1583933813717643e-05,
      "loss": 1.3172,
      "step": 4260
    },
    {
      "epoch": 1.7093674939951962,
      "grad_norm": 0.4895971417427063,
      "learning_rate": 2.1517213771016816e-05,
      "loss": 1.3818,
      "step": 4270
    },
    {
      "epoch": 1.713370696557246,
      "grad_norm": 0.6024243831634521,
      "learning_rate": 2.145049372831599e-05,
      "loss": 1.3438,
      "step": 4280
    },
    {
      "epoch": 1.7173738991192953,
      "grad_norm": 0.43368905782699585,
      "learning_rate": 2.138377368561516e-05,
      "loss": 1.5014,
      "step": 4290
    },
    {
      "epoch": 1.721377101681345,
      "grad_norm": 0.6243658661842346,
      "learning_rate": 2.1317053642914332e-05,
      "loss": 1.4325,
      "step": 4300
    },
    {
      "epoch": 1.7253803042433948,
      "grad_norm": 0.40887489914894104,
      "learning_rate": 2.1250333600213505e-05,
      "loss": 1.5817,
      "step": 4310
    },
    {
      "epoch": 1.7293835068054444,
      "grad_norm": 0.5005643367767334,
      "learning_rate": 2.118361355751268e-05,
      "loss": 1.2438,
      "step": 4320
    },
    {
      "epoch": 1.733386709367494,
      "grad_norm": 0.48897525668144226,
      "learning_rate": 2.111689351481185e-05,
      "loss": 1.5726,
      "step": 4330
    },
    {
      "epoch": 1.7373899119295437,
      "grad_norm": 0.4380977749824524,
      "learning_rate": 2.1050173472111025e-05,
      "loss": 1.437,
      "step": 4340
    },
    {
      "epoch": 1.7413931144915933,
      "grad_norm": 0.7820357084274292,
      "learning_rate": 2.0983453429410198e-05,
      "loss": 1.3574,
      "step": 4350
    },
    {
      "epoch": 1.7453963170536428,
      "grad_norm": 0.47708600759506226,
      "learning_rate": 2.091673338670937e-05,
      "loss": 1.3406,
      "step": 4360
    },
    {
      "epoch": 1.7493995196156926,
      "grad_norm": 0.49107280373573303,
      "learning_rate": 2.085001334400854e-05,
      "loss": 1.2384,
      "step": 4370
    },
    {
      "epoch": 1.7534027221777422,
      "grad_norm": 0.5127554535865784,
      "learning_rate": 2.0783293301307714e-05,
      "loss": 1.3478,
      "step": 4380
    },
    {
      "epoch": 1.7574059247397917,
      "grad_norm": 0.5927449464797974,
      "learning_rate": 2.0716573258606887e-05,
      "loss": 1.3723,
      "step": 4390
    },
    {
      "epoch": 1.7614091273018415,
      "grad_norm": 0.5684744119644165,
      "learning_rate": 2.064985321590606e-05,
      "loss": 1.3913,
      "step": 4400
    },
    {
      "epoch": 1.765412329863891,
      "grad_norm": 0.4752328395843506,
      "learning_rate": 2.0583133173205234e-05,
      "loss": 1.4088,
      "step": 4410
    },
    {
      "epoch": 1.7694155324259406,
      "grad_norm": 0.4487672448158264,
      "learning_rate": 2.0516413130504407e-05,
      "loss": 1.4559,
      "step": 4420
    },
    {
      "epoch": 1.7734187349879904,
      "grad_norm": 0.5163328647613525,
      "learning_rate": 2.0449693087803577e-05,
      "loss": 1.571,
      "step": 4430
    },
    {
      "epoch": 1.7774219375500402,
      "grad_norm": 0.5417699217796326,
      "learning_rate": 2.038297304510275e-05,
      "loss": 1.3598,
      "step": 4440
    },
    {
      "epoch": 1.7814251401120895,
      "grad_norm": 0.5205992460250854,
      "learning_rate": 2.0316253002401923e-05,
      "loss": 1.6076,
      "step": 4450
    },
    {
      "epoch": 1.7854283426741393,
      "grad_norm": 0.46954047679901123,
      "learning_rate": 2.0249532959701096e-05,
      "loss": 1.367,
      "step": 4460
    },
    {
      "epoch": 1.789431545236189,
      "grad_norm": 0.5495103597640991,
      "learning_rate": 2.018281291700027e-05,
      "loss": 1.313,
      "step": 4470
    },
    {
      "epoch": 1.7934347477982386,
      "grad_norm": 0.4486564099788666,
      "learning_rate": 2.0116092874299443e-05,
      "loss": 1.5428,
      "step": 4480
    },
    {
      "epoch": 1.7974379503602882,
      "grad_norm": 0.4783119261264801,
      "learning_rate": 2.0049372831598616e-05,
      "loss": 1.3309,
      "step": 4490
    },
    {
      "epoch": 1.801441152922338,
      "grad_norm": 0.48000073432922363,
      "learning_rate": 1.9982652788897786e-05,
      "loss": 1.3346,
      "step": 4500
    },
    {
      "epoch": 1.8054443554843875,
      "grad_norm": 0.5913456678390503,
      "learning_rate": 1.991593274619696e-05,
      "loss": 1.4106,
      "step": 4510
    },
    {
      "epoch": 1.809447558046437,
      "grad_norm": 0.470755398273468,
      "learning_rate": 1.9849212703496132e-05,
      "loss": 1.4596,
      "step": 4520
    },
    {
      "epoch": 1.8134507606084869,
      "grad_norm": 0.5511925220489502,
      "learning_rate": 1.9782492660795305e-05,
      "loss": 1.3909,
      "step": 4530
    },
    {
      "epoch": 1.8174539631705364,
      "grad_norm": 0.5095300674438477,
      "learning_rate": 1.971577261809448e-05,
      "loss": 1.395,
      "step": 4540
    },
    {
      "epoch": 1.821457165732586,
      "grad_norm": 0.5710403919219971,
      "learning_rate": 1.9649052575393652e-05,
      "loss": 1.4514,
      "step": 4550
    },
    {
      "epoch": 1.8254603682946358,
      "grad_norm": 0.5712993144989014,
      "learning_rate": 1.958233253269282e-05,
      "loss": 1.4279,
      "step": 4560
    },
    {
      "epoch": 1.8294635708566853,
      "grad_norm": 0.49004995822906494,
      "learning_rate": 1.9515612489991995e-05,
      "loss": 1.544,
      "step": 4570
    },
    {
      "epoch": 1.8334667734187349,
      "grad_norm": 0.46325254440307617,
      "learning_rate": 1.9448892447291168e-05,
      "loss": 1.4187,
      "step": 4580
    },
    {
      "epoch": 1.8374699759807847,
      "grad_norm": 0.5492123365402222,
      "learning_rate": 1.938217240459034e-05,
      "loss": 1.4564,
      "step": 4590
    },
    {
      "epoch": 1.8414731785428344,
      "grad_norm": 0.5002544522285461,
      "learning_rate": 1.9315452361889514e-05,
      "loss": 1.4892,
      "step": 4600
    },
    {
      "epoch": 1.8454763811048838,
      "grad_norm": 0.5926509499549866,
      "learning_rate": 1.9248732319188688e-05,
      "loss": 1.3815,
      "step": 4610
    },
    {
      "epoch": 1.8494795836669335,
      "grad_norm": 0.5012366771697998,
      "learning_rate": 1.9182012276487857e-05,
      "loss": 1.4141,
      "step": 4620
    },
    {
      "epoch": 1.8534827862289833,
      "grad_norm": 0.6875051259994507,
      "learning_rate": 1.911529223378703e-05,
      "loss": 1.2953,
      "step": 4630
    },
    {
      "epoch": 1.8574859887910327,
      "grad_norm": 0.41497600078582764,
      "learning_rate": 1.9048572191086204e-05,
      "loss": 1.3391,
      "step": 4640
    },
    {
      "epoch": 1.8614891913530824,
      "grad_norm": 0.6858248710632324,
      "learning_rate": 1.8981852148385377e-05,
      "loss": 1.4048,
      "step": 4650
    },
    {
      "epoch": 1.8654923939151322,
      "grad_norm": 0.533632218837738,
      "learning_rate": 1.891513210568455e-05,
      "loss": 1.3476,
      "step": 4660
    },
    {
      "epoch": 1.8694955964771818,
      "grad_norm": 0.5523557066917419,
      "learning_rate": 1.8848412062983723e-05,
      "loss": 1.4712,
      "step": 4670
    },
    {
      "epoch": 1.8734987990392313,
      "grad_norm": 0.5584340691566467,
      "learning_rate": 1.8781692020282893e-05,
      "loss": 1.3237,
      "step": 4680
    },
    {
      "epoch": 1.8775020016012811,
      "grad_norm": 0.43113622069358826,
      "learning_rate": 1.8714971977582066e-05,
      "loss": 1.3839,
      "step": 4690
    },
    {
      "epoch": 1.8815052041633307,
      "grad_norm": 0.5848178267478943,
      "learning_rate": 1.864825193488124e-05,
      "loss": 1.3719,
      "step": 4700
    },
    {
      "epoch": 1.8855084067253802,
      "grad_norm": 0.5803565979003906,
      "learning_rate": 1.8581531892180413e-05,
      "loss": 1.2814,
      "step": 4710
    },
    {
      "epoch": 1.88951160928743,
      "grad_norm": 0.4944668114185333,
      "learning_rate": 1.8514811849479586e-05,
      "loss": 1.4378,
      "step": 4720
    },
    {
      "epoch": 1.8935148118494796,
      "grad_norm": 0.5970917344093323,
      "learning_rate": 1.844809180677876e-05,
      "loss": 1.3594,
      "step": 4730
    },
    {
      "epoch": 1.8975180144115291,
      "grad_norm": 0.5410127639770508,
      "learning_rate": 1.838137176407793e-05,
      "loss": 1.4875,
      "step": 4740
    },
    {
      "epoch": 1.901521216973579,
      "grad_norm": 0.5484069585800171,
      "learning_rate": 1.8314651721377102e-05,
      "loss": 1.3568,
      "step": 4750
    },
    {
      "epoch": 1.9055244195356285,
      "grad_norm": 0.5327575206756592,
      "learning_rate": 1.8247931678676276e-05,
      "loss": 1.3037,
      "step": 4760
    },
    {
      "epoch": 1.909527622097678,
      "grad_norm": 0.5849072933197021,
      "learning_rate": 1.818121163597545e-05,
      "loss": 1.469,
      "step": 4770
    },
    {
      "epoch": 1.9135308246597278,
      "grad_norm": 0.5908790826797485,
      "learning_rate": 1.8114491593274622e-05,
      "loss": 1.4269,
      "step": 4780
    },
    {
      "epoch": 1.9175340272217776,
      "grad_norm": 0.39613479375839233,
      "learning_rate": 1.8047771550573795e-05,
      "loss": 1.4386,
      "step": 4790
    },
    {
      "epoch": 1.921537229783827,
      "grad_norm": 0.6419240832328796,
      "learning_rate": 1.7981051507872965e-05,
      "loss": 1.4379,
      "step": 4800
    },
    {
      "epoch": 1.9255404323458767,
      "grad_norm": 0.49787697196006775,
      "learning_rate": 1.7914331465172138e-05,
      "loss": 1.4397,
      "step": 4810
    },
    {
      "epoch": 1.9295436349079265,
      "grad_norm": 0.5405418276786804,
      "learning_rate": 1.784761142247131e-05,
      "loss": 1.4348,
      "step": 4820
    },
    {
      "epoch": 1.933546837469976,
      "grad_norm": 0.6142321228981018,
      "learning_rate": 1.7780891379770485e-05,
      "loss": 1.2061,
      "step": 4830
    },
    {
      "epoch": 1.9375500400320256,
      "grad_norm": 0.5297508835792542,
      "learning_rate": 1.7714171337069658e-05,
      "loss": 1.4396,
      "step": 4840
    },
    {
      "epoch": 1.9415532425940754,
      "grad_norm": 0.5713140964508057,
      "learning_rate": 1.764745129436883e-05,
      "loss": 1.2573,
      "step": 4850
    },
    {
      "epoch": 1.945556445156125,
      "grad_norm": 0.5472055077552795,
      "learning_rate": 1.7580731251668e-05,
      "loss": 1.5401,
      "step": 4860
    },
    {
      "epoch": 1.9495596477181745,
      "grad_norm": 0.46062779426574707,
      "learning_rate": 1.7514011208967174e-05,
      "loss": 1.4835,
      "step": 4870
    },
    {
      "epoch": 1.9535628502802243,
      "grad_norm": 0.643663763999939,
      "learning_rate": 1.7447291166266347e-05,
      "loss": 1.3373,
      "step": 4880
    },
    {
      "epoch": 1.9575660528422738,
      "grad_norm": 0.4524793028831482,
      "learning_rate": 1.738057112356552e-05,
      "loss": 1.3438,
      "step": 4890
    },
    {
      "epoch": 1.9615692554043234,
      "grad_norm": 0.430902898311615,
      "learning_rate": 1.7313851080864694e-05,
      "loss": 1.4258,
      "step": 4900
    },
    {
      "epoch": 1.9655724579663731,
      "grad_norm": 0.4790399670600891,
      "learning_rate": 1.7247131038163867e-05,
      "loss": 1.3309,
      "step": 4910
    },
    {
      "epoch": 1.9695756605284227,
      "grad_norm": 0.5086097717285156,
      "learning_rate": 1.7180410995463037e-05,
      "loss": 1.4638,
      "step": 4920
    },
    {
      "epoch": 1.9735788630904723,
      "grad_norm": 0.5293866395950317,
      "learning_rate": 1.711369095276221e-05,
      "loss": 1.4439,
      "step": 4930
    },
    {
      "epoch": 1.977582065652522,
      "grad_norm": 0.5068063735961914,
      "learning_rate": 1.7046970910061383e-05,
      "loss": 1.2571,
      "step": 4940
    },
    {
      "epoch": 1.9815852682145718,
      "grad_norm": 0.5501818656921387,
      "learning_rate": 1.6980250867360556e-05,
      "loss": 1.3829,
      "step": 4950
    },
    {
      "epoch": 1.9855884707766212,
      "grad_norm": 0.505294144153595,
      "learning_rate": 1.691353082465973e-05,
      "loss": 1.4545,
      "step": 4960
    },
    {
      "epoch": 1.989591673338671,
      "grad_norm": 0.6608362197875977,
      "learning_rate": 1.6846810781958903e-05,
      "loss": 1.2504,
      "step": 4970
    },
    {
      "epoch": 1.9935948759007207,
      "grad_norm": 0.7335928678512573,
      "learning_rate": 1.6780090739258076e-05,
      "loss": 1.4686,
      "step": 4980
    },
    {
      "epoch": 1.9975980784627703,
      "grad_norm": 0.5899332761764526,
      "learning_rate": 1.6713370696557246e-05,
      "loss": 1.2489,
      "step": 4990
    },
    {
      "epoch": 2.00160128102482,
      "grad_norm": 0.5002530813217163,
      "learning_rate": 1.664665065385642e-05,
      "loss": 1.2518,
      "step": 5000
    },
    {
      "epoch": 2.0056044835868696,
      "grad_norm": 0.6131898164749146,
      "learning_rate": 1.6579930611155592e-05,
      "loss": 1.4133,
      "step": 5010
    },
    {
      "epoch": 2.009607686148919,
      "grad_norm": 0.5485141277313232,
      "learning_rate": 1.6513210568454765e-05,
      "loss": 1.3339,
      "step": 5020
    },
    {
      "epoch": 2.0136108887109687,
      "grad_norm": 0.4647842049598694,
      "learning_rate": 1.644649052575394e-05,
      "loss": 1.4377,
      "step": 5030
    },
    {
      "epoch": 2.0176140912730185,
      "grad_norm": 0.5107964277267456,
      "learning_rate": 1.637977048305311e-05,
      "loss": 1.4586,
      "step": 5040
    },
    {
      "epoch": 2.0216172938350683,
      "grad_norm": 0.5226991772651672,
      "learning_rate": 1.631305044035228e-05,
      "loss": 1.3664,
      "step": 5050
    },
    {
      "epoch": 2.0256204963971176,
      "grad_norm": 0.7050232291221619,
      "learning_rate": 1.6246330397651455e-05,
      "loss": 1.4502,
      "step": 5060
    },
    {
      "epoch": 2.0296236989591674,
      "grad_norm": 0.5239764451980591,
      "learning_rate": 1.6179610354950628e-05,
      "loss": 1.3366,
      "step": 5070
    },
    {
      "epoch": 2.033626901521217,
      "grad_norm": 0.6744494438171387,
      "learning_rate": 1.61128903122498e-05,
      "loss": 1.5183,
      "step": 5080
    },
    {
      "epoch": 2.0376301040832665,
      "grad_norm": 0.4870768189430237,
      "learning_rate": 1.6046170269548974e-05,
      "loss": 1.3137,
      "step": 5090
    },
    {
      "epoch": 2.0416333066453163,
      "grad_norm": 0.6438353061676025,
      "learning_rate": 1.5979450226848147e-05,
      "loss": 1.4634,
      "step": 5100
    },
    {
      "epoch": 2.045636509207366,
      "grad_norm": 0.4888123869895935,
      "learning_rate": 1.5912730184147317e-05,
      "loss": 1.3444,
      "step": 5110
    },
    {
      "epoch": 2.0496397117694154,
      "grad_norm": 0.711000382900238,
      "learning_rate": 1.584601014144649e-05,
      "loss": 1.3675,
      "step": 5120
    },
    {
      "epoch": 2.053642914331465,
      "grad_norm": 0.6124823093414307,
      "learning_rate": 1.5779290098745664e-05,
      "loss": 1.3826,
      "step": 5130
    },
    {
      "epoch": 2.057646116893515,
      "grad_norm": 0.45651301741600037,
      "learning_rate": 1.5712570056044837e-05,
      "loss": 1.4047,
      "step": 5140
    },
    {
      "epoch": 2.0616493194555643,
      "grad_norm": 0.6101207733154297,
      "learning_rate": 1.564585001334401e-05,
      "loss": 1.4983,
      "step": 5150
    },
    {
      "epoch": 2.065652522017614,
      "grad_norm": 0.6344696283340454,
      "learning_rate": 1.5579129970643183e-05,
      "loss": 1.3815,
      "step": 5160
    },
    {
      "epoch": 2.069655724579664,
      "grad_norm": 0.5699716210365295,
      "learning_rate": 1.5512409927942353e-05,
      "loss": 1.3901,
      "step": 5170
    },
    {
      "epoch": 2.073658927141713,
      "grad_norm": 0.5727401971817017,
      "learning_rate": 1.5445689885241526e-05,
      "loss": 1.3616,
      "step": 5180
    },
    {
      "epoch": 2.077662129703763,
      "grad_norm": 0.44572892785072327,
      "learning_rate": 1.53789698425407e-05,
      "loss": 1.4172,
      "step": 5190
    },
    {
      "epoch": 2.0816653322658127,
      "grad_norm": 0.5314151644706726,
      "learning_rate": 1.5312249799839873e-05,
      "loss": 1.3985,
      "step": 5200
    },
    {
      "epoch": 2.085668534827862,
      "grad_norm": 0.49258700013160706,
      "learning_rate": 1.5245529757139046e-05,
      "loss": 1.3796,
      "step": 5210
    },
    {
      "epoch": 2.089671737389912,
      "grad_norm": 0.5560178756713867,
      "learning_rate": 1.5178809714438219e-05,
      "loss": 1.4702,
      "step": 5220
    },
    {
      "epoch": 2.0936749399519616,
      "grad_norm": 0.4853808283805847,
      "learning_rate": 1.5112089671737389e-05,
      "loss": 1.4215,
      "step": 5230
    },
    {
      "epoch": 2.0976781425140114,
      "grad_norm": 0.4617960453033447,
      "learning_rate": 1.5045369629036562e-05,
      "loss": 1.3947,
      "step": 5240
    },
    {
      "epoch": 2.1016813450760607,
      "grad_norm": 0.5264594554901123,
      "learning_rate": 1.4978649586335735e-05,
      "loss": 1.4317,
      "step": 5250
    },
    {
      "epoch": 2.1056845476381105,
      "grad_norm": 0.49758124351501465,
      "learning_rate": 1.4911929543634908e-05,
      "loss": 1.4431,
      "step": 5260
    },
    {
      "epoch": 2.1096877502001603,
      "grad_norm": 0.6294770836830139,
      "learning_rate": 1.4845209500934082e-05,
      "loss": 1.332,
      "step": 5270
    },
    {
      "epoch": 2.1136909527622096,
      "grad_norm": 0.5625954866409302,
      "learning_rate": 1.4778489458233255e-05,
      "loss": 1.2092,
      "step": 5280
    },
    {
      "epoch": 2.1176941553242594,
      "grad_norm": 0.49277591705322266,
      "learning_rate": 1.4711769415532425e-05,
      "loss": 1.3342,
      "step": 5290
    },
    {
      "epoch": 2.121697357886309,
      "grad_norm": 0.701707661151886,
      "learning_rate": 1.4645049372831598e-05,
      "loss": 1.414,
      "step": 5300
    },
    {
      "epoch": 2.1257005604483585,
      "grad_norm": 0.6993394494056702,
      "learning_rate": 1.4578329330130771e-05,
      "loss": 1.5038,
      "step": 5310
    },
    {
      "epoch": 2.1297037630104083,
      "grad_norm": 0.5076472759246826,
      "learning_rate": 1.4511609287429944e-05,
      "loss": 1.5505,
      "step": 5320
    },
    {
      "epoch": 2.133706965572458,
      "grad_norm": 0.4620603322982788,
      "learning_rate": 1.4444889244729117e-05,
      "loss": 1.314,
      "step": 5330
    },
    {
      "epoch": 2.1377101681345074,
      "grad_norm": 0.5558984279632568,
      "learning_rate": 1.437816920202829e-05,
      "loss": 1.3455,
      "step": 5340
    },
    {
      "epoch": 2.141713370696557,
      "grad_norm": 0.49363231658935547,
      "learning_rate": 1.4311449159327462e-05,
      "loss": 1.4211,
      "step": 5350
    },
    {
      "epoch": 2.145716573258607,
      "grad_norm": 0.5163969993591309,
      "learning_rate": 1.4244729116626634e-05,
      "loss": 1.3573,
      "step": 5360
    },
    {
      "epoch": 2.1497197758206563,
      "grad_norm": 0.7903188467025757,
      "learning_rate": 1.4178009073925807e-05,
      "loss": 1.4225,
      "step": 5370
    },
    {
      "epoch": 2.153722978382706,
      "grad_norm": 0.6300159692764282,
      "learning_rate": 1.411128903122498e-05,
      "loss": 1.4419,
      "step": 5380
    },
    {
      "epoch": 2.157726180944756,
      "grad_norm": 0.533305287361145,
      "learning_rate": 1.4044568988524153e-05,
      "loss": 1.2208,
      "step": 5390
    },
    {
      "epoch": 2.161729383506805,
      "grad_norm": 0.5113953948020935,
      "learning_rate": 1.3977848945823326e-05,
      "loss": 1.317,
      "step": 5400
    },
    {
      "epoch": 2.165732586068855,
      "grad_norm": 0.4573606848716736,
      "learning_rate": 1.3911128903122498e-05,
      "loss": 1.2835,
      "step": 5410
    },
    {
      "epoch": 2.1697357886309048,
      "grad_norm": 0.5437752604484558,
      "learning_rate": 1.3844408860421671e-05,
      "loss": 1.4751,
      "step": 5420
    },
    {
      "epoch": 2.1737389911929546,
      "grad_norm": 0.5271709561347961,
      "learning_rate": 1.3777688817720844e-05,
      "loss": 1.4207,
      "step": 5430
    },
    {
      "epoch": 2.177742193755004,
      "grad_norm": 0.5640484094619751,
      "learning_rate": 1.3710968775020016e-05,
      "loss": 1.3498,
      "step": 5440
    },
    {
      "epoch": 2.1817453963170537,
      "grad_norm": 0.5253577828407288,
      "learning_rate": 1.3644248732319189e-05,
      "loss": 1.3444,
      "step": 5450
    },
    {
      "epoch": 2.1857485988791034,
      "grad_norm": 0.6905509233474731,
      "learning_rate": 1.3577528689618362e-05,
      "loss": 1.2741,
      "step": 5460
    },
    {
      "epoch": 2.189751801441153,
      "grad_norm": 0.5476198792457581,
      "learning_rate": 1.3510808646917535e-05,
      "loss": 1.4051,
      "step": 5470
    },
    {
      "epoch": 2.1937550040032026,
      "grad_norm": 0.4454019367694855,
      "learning_rate": 1.3444088604216707e-05,
      "loss": 1.5321,
      "step": 5480
    },
    {
      "epoch": 2.1977582065652523,
      "grad_norm": 0.5111855268478394,
      "learning_rate": 1.337736856151588e-05,
      "loss": 1.3415,
      "step": 5490
    },
    {
      "epoch": 2.2017614091273017,
      "grad_norm": 0.5138364434242249,
      "learning_rate": 1.3310648518815053e-05,
      "loss": 1.3383,
      "step": 5500
    },
    {
      "epoch": 2.2057646116893515,
      "grad_norm": 0.49963411688804626,
      "learning_rate": 1.3243928476114227e-05,
      "loss": 1.3316,
      "step": 5510
    },
    {
      "epoch": 2.2097678142514012,
      "grad_norm": 0.5816958546638489,
      "learning_rate": 1.3177208433413398e-05,
      "loss": 1.4321,
      "step": 5520
    },
    {
      "epoch": 2.2137710168134506,
      "grad_norm": 0.5255439281463623,
      "learning_rate": 1.3110488390712571e-05,
      "loss": 1.458,
      "step": 5530
    },
    {
      "epoch": 2.2177742193755003,
      "grad_norm": 0.6404129862785339,
      "learning_rate": 1.3043768348011743e-05,
      "loss": 1.3272,
      "step": 5540
    },
    {
      "epoch": 2.22177742193755,
      "grad_norm": 0.6640493869781494,
      "learning_rate": 1.2977048305310916e-05,
      "loss": 1.4073,
      "step": 5550
    },
    {
      "epoch": 2.2257806244996,
      "grad_norm": 0.5673337578773499,
      "learning_rate": 1.2910328262610089e-05,
      "loss": 1.3036,
      "step": 5560
    },
    {
      "epoch": 2.2297838270616492,
      "grad_norm": 0.5478885173797607,
      "learning_rate": 1.2843608219909262e-05,
      "loss": 1.4138,
      "step": 5570
    },
    {
      "epoch": 2.233787029623699,
      "grad_norm": 0.6397110819816589,
      "learning_rate": 1.2776888177208436e-05,
      "loss": 1.3003,
      "step": 5580
    },
    {
      "epoch": 2.237790232185749,
      "grad_norm": 0.5010491013526917,
      "learning_rate": 1.2710168134507609e-05,
      "loss": 1.3867,
      "step": 5590
    },
    {
      "epoch": 2.241793434747798,
      "grad_norm": 0.5216848254203796,
      "learning_rate": 1.2643448091806779e-05,
      "loss": 1.1958,
      "step": 5600
    },
    {
      "epoch": 2.245796637309848,
      "grad_norm": 0.5485367774963379,
      "learning_rate": 1.2576728049105952e-05,
      "loss": 1.481,
      "step": 5610
    },
    {
      "epoch": 2.2497998398718977,
      "grad_norm": 0.5161309242248535,
      "learning_rate": 1.2510008006405125e-05,
      "loss": 1.3877,
      "step": 5620
    },
    {
      "epoch": 2.253803042433947,
      "grad_norm": 0.5105531215667725,
      "learning_rate": 1.2443287963704298e-05,
      "loss": 1.3895,
      "step": 5630
    },
    {
      "epoch": 2.257806244995997,
      "grad_norm": 0.8766815066337585,
      "learning_rate": 1.237656792100347e-05,
      "loss": 1.3551,
      "step": 5640
    },
    {
      "epoch": 2.2618094475580466,
      "grad_norm": 0.5295102596282959,
      "learning_rate": 1.2309847878302643e-05,
      "loss": 1.458,
      "step": 5650
    },
    {
      "epoch": 2.265812650120096,
      "grad_norm": 0.7106857299804688,
      "learning_rate": 1.2243127835601816e-05,
      "loss": 1.2943,
      "step": 5660
    },
    {
      "epoch": 2.2698158526821457,
      "grad_norm": 0.6345118284225464,
      "learning_rate": 1.217640779290099e-05,
      "loss": 1.4462,
      "step": 5670
    },
    {
      "epoch": 2.2738190552441955,
      "grad_norm": 0.7667320966720581,
      "learning_rate": 1.210968775020016e-05,
      "loss": 1.447,
      "step": 5680
    },
    {
      "epoch": 2.277822257806245,
      "grad_norm": 0.5316633582115173,
      "learning_rate": 1.2042967707499334e-05,
      "loss": 1.4945,
      "step": 5690
    },
    {
      "epoch": 2.2818254603682946,
      "grad_norm": 0.6558210253715515,
      "learning_rate": 1.1976247664798507e-05,
      "loss": 1.3153,
      "step": 5700
    },
    {
      "epoch": 2.2858286629303444,
      "grad_norm": 0.519717276096344,
      "learning_rate": 1.1909527622097679e-05,
      "loss": 1.434,
      "step": 5710
    },
    {
      "epoch": 2.2898318654923937,
      "grad_norm": 0.5795550346374512,
      "learning_rate": 1.1842807579396852e-05,
      "loss": 1.3942,
      "step": 5720
    },
    {
      "epoch": 2.2938350680544435,
      "grad_norm": 0.5574532151222229,
      "learning_rate": 1.1776087536696025e-05,
      "loss": 1.2481,
      "step": 5730
    },
    {
      "epoch": 2.2978382706164933,
      "grad_norm": 0.4853678345680237,
      "learning_rate": 1.1709367493995197e-05,
      "loss": 1.5394,
      "step": 5740
    },
    {
      "epoch": 2.301841473178543,
      "grad_norm": 0.6109431982040405,
      "learning_rate": 1.164264745129437e-05,
      "loss": 1.3945,
      "step": 5750
    },
    {
      "epoch": 2.3058446757405924,
      "grad_norm": 0.5409573316574097,
      "learning_rate": 1.1575927408593543e-05,
      "loss": 1.4645,
      "step": 5760
    },
    {
      "epoch": 2.309847878302642,
      "grad_norm": 0.6094141602516174,
      "learning_rate": 1.1509207365892714e-05,
      "loss": 1.3539,
      "step": 5770
    },
    {
      "epoch": 2.313851080864692,
      "grad_norm": 0.5452346801757812,
      "learning_rate": 1.1442487323191888e-05,
      "loss": 1.38,
      "step": 5780
    },
    {
      "epoch": 2.3178542834267413,
      "grad_norm": 0.779553234577179,
      "learning_rate": 1.1375767280491061e-05,
      "loss": 1.3457,
      "step": 5790
    },
    {
      "epoch": 2.321857485988791,
      "grad_norm": 0.508877694606781,
      "learning_rate": 1.1309047237790232e-05,
      "loss": 1.4849,
      "step": 5800
    },
    {
      "epoch": 2.325860688550841,
      "grad_norm": 0.6125603318214417,
      "learning_rate": 1.1242327195089406e-05,
      "loss": 1.3492,
      "step": 5810
    },
    {
      "epoch": 2.32986389111289,
      "grad_norm": 0.5610405802726746,
      "learning_rate": 1.1175607152388579e-05,
      "loss": 1.262,
      "step": 5820
    },
    {
      "epoch": 2.33386709367494,
      "grad_norm": 0.49269089102745056,
      "learning_rate": 1.110888710968775e-05,
      "loss": 1.4316,
      "step": 5830
    },
    {
      "epoch": 2.3378702962369897,
      "grad_norm": 0.5225329995155334,
      "learning_rate": 1.1042167066986923e-05,
      "loss": 1.2598,
      "step": 5840
    },
    {
      "epoch": 2.341873498799039,
      "grad_norm": 0.4773133397102356,
      "learning_rate": 1.0975447024286097e-05,
      "loss": 1.4428,
      "step": 5850
    },
    {
      "epoch": 2.345876701361089,
      "grad_norm": 0.5295489430427551,
      "learning_rate": 1.0908726981585268e-05,
      "loss": 1.3557,
      "step": 5860
    },
    {
      "epoch": 2.3498799039231386,
      "grad_norm": 0.5414580702781677,
      "learning_rate": 1.0842006938884441e-05,
      "loss": 1.3518,
      "step": 5870
    },
    {
      "epoch": 2.3538831064851884,
      "grad_norm": 0.5919463634490967,
      "learning_rate": 1.0775286896183615e-05,
      "loss": 1.3375,
      "step": 5880
    },
    {
      "epoch": 2.3578863090472377,
      "grad_norm": 0.605512797832489,
      "learning_rate": 1.0708566853482786e-05,
      "loss": 1.5308,
      "step": 5890
    },
    {
      "epoch": 2.3618895116092875,
      "grad_norm": 0.5035421848297119,
      "learning_rate": 1.064184681078196e-05,
      "loss": 1.3385,
      "step": 5900
    },
    {
      "epoch": 2.365892714171337,
      "grad_norm": 0.5493327379226685,
      "learning_rate": 1.0575126768081133e-05,
      "loss": 1.3421,
      "step": 5910
    },
    {
      "epoch": 2.3698959167333866,
      "grad_norm": 0.52861088514328,
      "learning_rate": 1.0508406725380304e-05,
      "loss": 1.3964,
      "step": 5920
    },
    {
      "epoch": 2.3738991192954364,
      "grad_norm": 0.6142955422401428,
      "learning_rate": 1.0441686682679477e-05,
      "loss": 1.3978,
      "step": 5930
    },
    {
      "epoch": 2.377902321857486,
      "grad_norm": 0.5488834381103516,
      "learning_rate": 1.037496663997865e-05,
      "loss": 1.3532,
      "step": 5940
    },
    {
      "epoch": 2.3819055244195355,
      "grad_norm": 0.44778865575790405,
      "learning_rate": 1.0308246597277822e-05,
      "loss": 1.5055,
      "step": 5950
    },
    {
      "epoch": 2.3859087269815853,
      "grad_norm": 0.7563341856002808,
      "learning_rate": 1.0241526554576995e-05,
      "loss": 1.3228,
      "step": 5960
    },
    {
      "epoch": 2.389911929543635,
      "grad_norm": 0.582499623298645,
      "learning_rate": 1.0174806511876168e-05,
      "loss": 1.3213,
      "step": 5970
    },
    {
      "epoch": 2.3939151321056844,
      "grad_norm": 0.6108660101890564,
      "learning_rate": 1.010808646917534e-05,
      "loss": 1.4082,
      "step": 5980
    },
    {
      "epoch": 2.397918334667734,
      "grad_norm": 0.5956066846847534,
      "learning_rate": 1.0041366426474513e-05,
      "loss": 1.2658,
      "step": 5990
    },
    {
      "epoch": 2.401921537229784,
      "grad_norm": 0.5614805817604065,
      "learning_rate": 9.974646383773686e-06,
      "loss": 1.5655,
      "step": 6000
    },
    {
      "epoch": 2.4059247397918333,
      "grad_norm": 0.5642668008804321,
      "learning_rate": 9.907926341072858e-06,
      "loss": 1.3661,
      "step": 6010
    },
    {
      "epoch": 2.409927942353883,
      "grad_norm": 0.5524826645851135,
      "learning_rate": 9.841206298372031e-06,
      "loss": 1.3866,
      "step": 6020
    },
    {
      "epoch": 2.413931144915933,
      "grad_norm": 0.6053515672683716,
      "learning_rate": 9.774486255671204e-06,
      "loss": 1.3757,
      "step": 6030
    },
    {
      "epoch": 2.417934347477982,
      "grad_norm": 0.5131747722625732,
      "learning_rate": 9.707766212970376e-06,
      "loss": 1.383,
      "step": 6040
    },
    {
      "epoch": 2.421937550040032,
      "grad_norm": 0.5066239237785339,
      "learning_rate": 9.641046170269549e-06,
      "loss": 1.5134,
      "step": 6050
    },
    {
      "epoch": 2.4259407526020818,
      "grad_norm": 0.5809990167617798,
      "learning_rate": 9.574326127568722e-06,
      "loss": 1.389,
      "step": 6060
    },
    {
      "epoch": 2.4299439551641315,
      "grad_norm": 0.5204609036445618,
      "learning_rate": 9.507606084867894e-06,
      "loss": 1.2697,
      "step": 6070
    },
    {
      "epoch": 2.433947157726181,
      "grad_norm": 0.5715891718864441,
      "learning_rate": 9.440886042167067e-06,
      "loss": 1.4891,
      "step": 6080
    },
    {
      "epoch": 2.4379503602882306,
      "grad_norm": 0.4999695420265198,
      "learning_rate": 9.37416599946624e-06,
      "loss": 1.3851,
      "step": 6090
    },
    {
      "epoch": 2.44195356285028,
      "grad_norm": 0.4789108335971832,
      "learning_rate": 9.307445956765411e-06,
      "loss": 1.3129,
      "step": 6100
    },
    {
      "epoch": 2.4459567654123298,
      "grad_norm": 0.5941859483718872,
      "learning_rate": 9.240725914064585e-06,
      "loss": 1.4054,
      "step": 6110
    },
    {
      "epoch": 2.4499599679743795,
      "grad_norm": 0.5595842003822327,
      "learning_rate": 9.174005871363758e-06,
      "loss": 1.2743,
      "step": 6120
    },
    {
      "epoch": 2.4539631705364293,
      "grad_norm": 0.5814018845558167,
      "learning_rate": 9.107285828662931e-06,
      "loss": 1.4341,
      "step": 6130
    },
    {
      "epoch": 2.4579663730984787,
      "grad_norm": 0.45942091941833496,
      "learning_rate": 9.040565785962103e-06,
      "loss": 1.3821,
      "step": 6140
    },
    {
      "epoch": 2.4619695756605284,
      "grad_norm": 0.502356231212616,
      "learning_rate": 8.973845743261276e-06,
      "loss": 1.29,
      "step": 6150
    },
    {
      "epoch": 2.465972778222578,
      "grad_norm": 0.511388897895813,
      "learning_rate": 8.907125700560449e-06,
      "loss": 1.445,
      "step": 6160
    },
    {
      "epoch": 2.4699759807846275,
      "grad_norm": 0.5695554614067078,
      "learning_rate": 8.84040565785962e-06,
      "loss": 1.3526,
      "step": 6170
    },
    {
      "epoch": 2.4739791833466773,
      "grad_norm": 0.49551475048065186,
      "learning_rate": 8.773685615158794e-06,
      "loss": 1.3695,
      "step": 6180
    },
    {
      "epoch": 2.477982385908727,
      "grad_norm": 0.4661310911178589,
      "learning_rate": 8.706965572457967e-06,
      "loss": 1.3786,
      "step": 6190
    },
    {
      "epoch": 2.4819855884707764,
      "grad_norm": 0.5555314421653748,
      "learning_rate": 8.640245529757138e-06,
      "loss": 1.4214,
      "step": 6200
    },
    {
      "epoch": 2.485988791032826,
      "grad_norm": 0.5755524039268494,
      "learning_rate": 8.573525487056312e-06,
      "loss": 1.3643,
      "step": 6210
    },
    {
      "epoch": 2.489991993594876,
      "grad_norm": 0.6725972294807434,
      "learning_rate": 8.506805444355485e-06,
      "loss": 1.4196,
      "step": 6220
    },
    {
      "epoch": 2.4939951961569253,
      "grad_norm": 0.4713147282600403,
      "learning_rate": 8.440085401654656e-06,
      "loss": 1.332,
      "step": 6230
    },
    {
      "epoch": 2.497998398718975,
      "grad_norm": 0.6595853567123413,
      "learning_rate": 8.37336535895383e-06,
      "loss": 1.3614,
      "step": 6240
    },
    {
      "epoch": 2.502001601281025,
      "grad_norm": 0.5247213840484619,
      "learning_rate": 8.306645316253003e-06,
      "loss": 1.3895,
      "step": 6250
    },
    {
      "epoch": 2.5060048038430747,
      "grad_norm": 0.514821469783783,
      "learning_rate": 8.239925273552176e-06,
      "loss": 1.3465,
      "step": 6260
    },
    {
      "epoch": 2.510008006405124,
      "grad_norm": 0.5179848670959473,
      "learning_rate": 8.173205230851347e-06,
      "loss": 1.2072,
      "step": 6270
    },
    {
      "epoch": 2.514011208967174,
      "grad_norm": 0.473950058221817,
      "learning_rate": 8.10648518815052e-06,
      "loss": 1.465,
      "step": 6280
    },
    {
      "epoch": 2.518014411529223,
      "grad_norm": 0.5973525047302246,
      "learning_rate": 8.039765145449694e-06,
      "loss": 1.2902,
      "step": 6290
    },
    {
      "epoch": 2.522017614091273,
      "grad_norm": 0.5501605272293091,
      "learning_rate": 7.973045102748867e-06,
      "loss": 1.3949,
      "step": 6300
    },
    {
      "epoch": 2.5260208166533227,
      "grad_norm": 0.5151085257530212,
      "learning_rate": 7.906325060048038e-06,
      "loss": 1.3874,
      "step": 6310
    },
    {
      "epoch": 2.5300240192153725,
      "grad_norm": 0.569076418876648,
      "learning_rate": 7.839605017347212e-06,
      "loss": 1.3027,
      "step": 6320
    },
    {
      "epoch": 2.534027221777422,
      "grad_norm": 0.4929979741573334,
      "learning_rate": 7.772884974646385e-06,
      "loss": 1.2727,
      "step": 6330
    },
    {
      "epoch": 2.5380304243394716,
      "grad_norm": 0.5316853523254395,
      "learning_rate": 7.706164931945558e-06,
      "loss": 1.5342,
      "step": 6340
    },
    {
      "epoch": 2.5420336269015213,
      "grad_norm": 0.7987499833106995,
      "learning_rate": 7.63944488924473e-06,
      "loss": 1.2821,
      "step": 6350
    },
    {
      "epoch": 2.5460368294635707,
      "grad_norm": 0.6210328340530396,
      "learning_rate": 7.572724846543902e-06,
      "loss": 1.4919,
      "step": 6360
    },
    {
      "epoch": 2.5500400320256205,
      "grad_norm": 0.5733069777488708,
      "learning_rate": 7.506004803843075e-06,
      "loss": 1.2871,
      "step": 6370
    },
    {
      "epoch": 2.5540432345876702,
      "grad_norm": 0.5469390749931335,
      "learning_rate": 7.439284761142247e-06,
      "loss": 1.4624,
      "step": 6380
    },
    {
      "epoch": 2.55804643714972,
      "grad_norm": 0.46260955929756165,
      "learning_rate": 7.37256471844142e-06,
      "loss": 1.3941,
      "step": 6390
    },
    {
      "epoch": 2.5620496397117694,
      "grad_norm": 0.5328449010848999,
      "learning_rate": 7.305844675740593e-06,
      "loss": 1.3994,
      "step": 6400
    },
    {
      "epoch": 2.566052842273819,
      "grad_norm": 0.5029089450836182,
      "learning_rate": 7.2391246330397646e-06,
      "loss": 1.4631,
      "step": 6410
    },
    {
      "epoch": 2.5700560448358685,
      "grad_norm": 0.4528283178806305,
      "learning_rate": 7.172404590338938e-06,
      "loss": 1.2815,
      "step": 6420
    },
    {
      "epoch": 2.5740592473979182,
      "grad_norm": 0.5331394076347351,
      "learning_rate": 7.105684547638111e-06,
      "loss": 1.4021,
      "step": 6430
    },
    {
      "epoch": 2.578062449959968,
      "grad_norm": 0.6235454082489014,
      "learning_rate": 7.038964504937283e-06,
      "loss": 1.3227,
      "step": 6440
    },
    {
      "epoch": 2.582065652522018,
      "grad_norm": 0.5304275751113892,
      "learning_rate": 6.972244462236456e-06,
      "loss": 1.3517,
      "step": 6450
    },
    {
      "epoch": 2.586068855084067,
      "grad_norm": 0.5872631669044495,
      "learning_rate": 6.905524419535629e-06,
      "loss": 1.4455,
      "step": 6460
    },
    {
      "epoch": 2.590072057646117,
      "grad_norm": 0.6492648124694824,
      "learning_rate": 6.838804376834801e-06,
      "loss": 1.3263,
      "step": 6470
    },
    {
      "epoch": 2.5940752602081663,
      "grad_norm": 0.6526904106140137,
      "learning_rate": 6.772084334133974e-06,
      "loss": 1.3917,
      "step": 6480
    },
    {
      "epoch": 2.598078462770216,
      "grad_norm": 0.5660387277603149,
      "learning_rate": 6.705364291433147e-06,
      "loss": 1.3906,
      "step": 6490
    },
    {
      "epoch": 2.602081665332266,
      "grad_norm": 0.5593698024749756,
      "learning_rate": 6.638644248732319e-06,
      "loss": 1.3771,
      "step": 6500
    },
    {
      "epoch": 2.6060848678943156,
      "grad_norm": 0.5729269981384277,
      "learning_rate": 6.571924206031492e-06,
      "loss": 1.4058,
      "step": 6510
    },
    {
      "epoch": 2.610088070456365,
      "grad_norm": 0.5443128347396851,
      "learning_rate": 6.5052041633306655e-06,
      "loss": 1.4901,
      "step": 6520
    },
    {
      "epoch": 2.6140912730184147,
      "grad_norm": 0.5757585167884827,
      "learning_rate": 6.438484120629837e-06,
      "loss": 1.2744,
      "step": 6530
    },
    {
      "epoch": 2.6180944755804645,
      "grad_norm": 0.6169623732566833,
      "learning_rate": 6.37176407792901e-06,
      "loss": 1.401,
      "step": 6540
    },
    {
      "epoch": 2.622097678142514,
      "grad_norm": 0.7411690950393677,
      "learning_rate": 6.3050440352281834e-06,
      "loss": 1.4132,
      "step": 6550
    },
    {
      "epoch": 2.6261008807045636,
      "grad_norm": 0.6434290409088135,
      "learning_rate": 6.238323992527356e-06,
      "loss": 1.3548,
      "step": 6560
    },
    {
      "epoch": 2.6301040832666134,
      "grad_norm": 0.4981061816215515,
      "learning_rate": 6.171603949826528e-06,
      "loss": 1.419,
      "step": 6570
    },
    {
      "epoch": 2.634107285828663,
      "grad_norm": 0.47985774278640747,
      "learning_rate": 6.104883907125701e-06,
      "loss": 1.3518,
      "step": 6580
    },
    {
      "epoch": 2.6381104883907125,
      "grad_norm": 0.5604844689369202,
      "learning_rate": 6.038163864424874e-06,
      "loss": 1.4396,
      "step": 6590
    },
    {
      "epoch": 2.6421136909527623,
      "grad_norm": 0.5351051092147827,
      "learning_rate": 5.971443821724046e-06,
      "loss": 1.188,
      "step": 6600
    },
    {
      "epoch": 2.6461168935148116,
      "grad_norm": 0.5802916884422302,
      "learning_rate": 5.904723779023219e-06,
      "loss": 1.4342,
      "step": 6610
    },
    {
      "epoch": 2.6501200960768614,
      "grad_norm": 0.6097198724746704,
      "learning_rate": 5.838003736322392e-06,
      "loss": 1.3149,
      "step": 6620
    },
    {
      "epoch": 2.654123298638911,
      "grad_norm": 0.4491061866283417,
      "learning_rate": 5.771283693621564e-06,
      "loss": 1.3726,
      "step": 6630
    },
    {
      "epoch": 2.658126501200961,
      "grad_norm": 0.6771233081817627,
      "learning_rate": 5.704563650920737e-06,
      "loss": 1.4374,
      "step": 6640
    },
    {
      "epoch": 2.6621297037630103,
      "grad_norm": 0.777606725692749,
      "learning_rate": 5.6378436082199095e-06,
      "loss": 1.458,
      "step": 6650
    },
    {
      "epoch": 2.66613290632506,
      "grad_norm": 0.5038171410560608,
      "learning_rate": 5.571123565519082e-06,
      "loss": 1.2933,
      "step": 6660
    },
    {
      "epoch": 2.67013610888711,
      "grad_norm": 0.621758222579956,
      "learning_rate": 5.504403522818255e-06,
      "loss": 1.3952,
      "step": 6670
    },
    {
      "epoch": 2.674139311449159,
      "grad_norm": 0.5314202904701233,
      "learning_rate": 5.437683480117427e-06,
      "loss": 1.4691,
      "step": 6680
    },
    {
      "epoch": 2.678142514011209,
      "grad_norm": 0.6527828574180603,
      "learning_rate": 5.370963437416601e-06,
      "loss": 1.478,
      "step": 6690
    },
    {
      "epoch": 2.6821457165732587,
      "grad_norm": 0.4793233275413513,
      "learning_rate": 5.304243394715773e-06,
      "loss": 1.3216,
      "step": 6700
    },
    {
      "epoch": 2.6861489191353085,
      "grad_norm": 0.6196656227111816,
      "learning_rate": 5.237523352014945e-06,
      "loss": 1.3981,
      "step": 6710
    },
    {
      "epoch": 2.690152121697358,
      "grad_norm": 0.6344252228736877,
      "learning_rate": 5.1708033093141185e-06,
      "loss": 1.4338,
      "step": 6720
    },
    {
      "epoch": 2.6941553242594076,
      "grad_norm": 0.5408412218093872,
      "learning_rate": 5.104083266613291e-06,
      "loss": 1.3985,
      "step": 6730
    },
    {
      "epoch": 2.698158526821457,
      "grad_norm": 0.5377091765403748,
      "learning_rate": 5.037363223912463e-06,
      "loss": 1.462,
      "step": 6740
    },
    {
      "epoch": 2.7021617293835067,
      "grad_norm": 0.5039907693862915,
      "learning_rate": 4.970643181211636e-06,
      "loss": 1.3493,
      "step": 6750
    },
    {
      "epoch": 2.7061649319455565,
      "grad_norm": 0.5019012093544006,
      "learning_rate": 4.903923138510809e-06,
      "loss": 1.39,
      "step": 6760
    },
    {
      "epoch": 2.7101681345076063,
      "grad_norm": 0.6031912565231323,
      "learning_rate": 4.837203095809981e-06,
      "loss": 1.377,
      "step": 6770
    },
    {
      "epoch": 2.7141713370696556,
      "grad_norm": 0.5002680420875549,
      "learning_rate": 4.770483053109154e-06,
      "loss": 1.3802,
      "step": 6780
    },
    {
      "epoch": 2.7181745396317054,
      "grad_norm": 0.5703972578048706,
      "learning_rate": 4.703763010408327e-06,
      "loss": 1.4463,
      "step": 6790
    },
    {
      "epoch": 2.7221777421937547,
      "grad_norm": 0.5380725860595703,
      "learning_rate": 4.637042967707499e-06,
      "loss": 1.2738,
      "step": 6800
    },
    {
      "epoch": 2.7261809447558045,
      "grad_norm": 0.5402765274047852,
      "learning_rate": 4.570322925006672e-06,
      "loss": 1.4043,
      "step": 6810
    },
    {
      "epoch": 2.7301841473178543,
      "grad_norm": 0.47025206685066223,
      "learning_rate": 4.503602882305845e-06,
      "loss": 1.438,
      "step": 6820
    },
    {
      "epoch": 2.734187349879904,
      "grad_norm": 0.5755069255828857,
      "learning_rate": 4.436882839605017e-06,
      "loss": 1.3567,
      "step": 6830
    },
    {
      "epoch": 2.7381905524419534,
      "grad_norm": 0.5449039340019226,
      "learning_rate": 4.37016279690419e-06,
      "loss": 1.4903,
      "step": 6840
    },
    {
      "epoch": 2.742193755004003,
      "grad_norm": 0.7005590796470642,
      "learning_rate": 4.3034427542033625e-06,
      "loss": 1.4319,
      "step": 6850
    },
    {
      "epoch": 2.746196957566053,
      "grad_norm": 0.5081183314323425,
      "learning_rate": 4.236722711502536e-06,
      "loss": 1.4419,
      "step": 6860
    },
    {
      "epoch": 2.7502001601281023,
      "grad_norm": 0.5886406302452087,
      "learning_rate": 4.170002668801708e-06,
      "loss": 1.4701,
      "step": 6870
    },
    {
      "epoch": 2.754203362690152,
      "grad_norm": 0.6271598935127258,
      "learning_rate": 4.103282626100881e-06,
      "loss": 1.3121,
      "step": 6880
    },
    {
      "epoch": 2.758206565252202,
      "grad_norm": 0.5756451487541199,
      "learning_rate": 4.036562583400054e-06,
      "loss": 1.5072,
      "step": 6890
    },
    {
      "epoch": 2.7622097678142516,
      "grad_norm": 0.4775222837924957,
      "learning_rate": 3.969842540699227e-06,
      "loss": 1.3915,
      "step": 6900
    },
    {
      "epoch": 2.766212970376301,
      "grad_norm": 0.50252366065979,
      "learning_rate": 3.903122497998399e-06,
      "loss": 1.3461,
      "step": 6910
    },
    {
      "epoch": 2.7702161729383508,
      "grad_norm": 0.5768641233444214,
      "learning_rate": 3.8364024552975715e-06,
      "loss": 1.3939,
      "step": 6920
    },
    {
      "epoch": 2.7742193755004,
      "grad_norm": 0.5696033835411072,
      "learning_rate": 3.7696824125967443e-06,
      "loss": 1.3122,
      "step": 6930
    },
    {
      "epoch": 2.77822257806245,
      "grad_norm": 0.4295739233493805,
      "learning_rate": 3.7029623698959166e-06,
      "loss": 1.4691,
      "step": 6940
    },
    {
      "epoch": 2.7822257806244997,
      "grad_norm": 0.7065779566764832,
      "learning_rate": 3.63624232719509e-06,
      "loss": 1.4018,
      "step": 6950
    },
    {
      "epoch": 2.7862289831865494,
      "grad_norm": 0.5798749923706055,
      "learning_rate": 3.569522284494262e-06,
      "loss": 1.52,
      "step": 6960
    },
    {
      "epoch": 2.7902321857485988,
      "grad_norm": 0.5953952670097351,
      "learning_rate": 3.502802241793435e-06,
      "loss": 1.309,
      "step": 6970
    },
    {
      "epoch": 2.7942353883106485,
      "grad_norm": 0.5521077513694763,
      "learning_rate": 3.4360821990926077e-06,
      "loss": 1.4546,
      "step": 6980
    },
    {
      "epoch": 2.798238590872698,
      "grad_norm": 0.48257073760032654,
      "learning_rate": 3.36936215639178e-06,
      "loss": 1.4187,
      "step": 6990
    },
    {
      "epoch": 2.8022417934347477,
      "grad_norm": 0.6572533845901489,
      "learning_rate": 3.302642113690953e-06,
      "loss": 1.3432,
      "step": 7000
    },
    {
      "epoch": 2.8062449959967974,
      "grad_norm": 0.4918784499168396,
      "learning_rate": 3.2359220709901256e-06,
      "loss": 1.3415,
      "step": 7010
    },
    {
      "epoch": 2.810248198558847,
      "grad_norm": 0.5094262957572937,
      "learning_rate": 3.1692020282892984e-06,
      "loss": 1.3359,
      "step": 7020
    },
    {
      "epoch": 2.8142514011208966,
      "grad_norm": 0.6041995882987976,
      "learning_rate": 3.102481985588471e-06,
      "loss": 1.4226,
      "step": 7030
    },
    {
      "epoch": 2.8182546036829463,
      "grad_norm": 0.5510640144348145,
      "learning_rate": 3.0357619428876435e-06,
      "loss": 1.4287,
      "step": 7040
    },
    {
      "epoch": 2.822257806244996,
      "grad_norm": 0.5016040802001953,
      "learning_rate": 2.9690419001868163e-06,
      "loss": 1.353,
      "step": 7050
    },
    {
      "epoch": 2.8262610088070454,
      "grad_norm": 0.5591461062431335,
      "learning_rate": 2.902321857485989e-06,
      "loss": 1.3827,
      "step": 7060
    },
    {
      "epoch": 2.8302642113690952,
      "grad_norm": 0.6099066138267517,
      "learning_rate": 2.8356018147851614e-06,
      "loss": 1.4066,
      "step": 7070
    },
    {
      "epoch": 2.834267413931145,
      "grad_norm": 0.6606244444847107,
      "learning_rate": 2.7688817720843342e-06,
      "loss": 1.3325,
      "step": 7080
    },
    {
      "epoch": 2.838270616493195,
      "grad_norm": 0.4910116493701935,
      "learning_rate": 2.702161729383507e-06,
      "loss": 1.2968,
      "step": 7090
    },
    {
      "epoch": 2.842273819055244,
      "grad_norm": 0.5171888470649719,
      "learning_rate": 2.6354416866826798e-06,
      "loss": 1.4946,
      "step": 7100
    },
    {
      "epoch": 2.846277021617294,
      "grad_norm": 0.5235945582389832,
      "learning_rate": 2.568721643981852e-06,
      "loss": 1.3177,
      "step": 7110
    },
    {
      "epoch": 2.8502802241793432,
      "grad_norm": 0.5755864977836609,
      "learning_rate": 2.502001601281025e-06,
      "loss": 1.4312,
      "step": 7120
    },
    {
      "epoch": 2.854283426741393,
      "grad_norm": 0.5582333207130432,
      "learning_rate": 2.4352815585801977e-06,
      "loss": 1.3666,
      "step": 7130
    },
    {
      "epoch": 2.858286629303443,
      "grad_norm": 0.5005878806114197,
      "learning_rate": 2.36856151587937e-06,
      "loss": 1.4448,
      "step": 7140
    },
    {
      "epoch": 2.8622898318654926,
      "grad_norm": 0.6505551338195801,
      "learning_rate": 2.301841473178543e-06,
      "loss": 1.3373,
      "step": 7150
    },
    {
      "epoch": 2.866293034427542,
      "grad_norm": 0.5298516750335693,
      "learning_rate": 2.2351214304777156e-06,
      "loss": 1.4261,
      "step": 7160
    },
    {
      "epoch": 2.8702962369895917,
      "grad_norm": 0.7670217156410217,
      "learning_rate": 2.168401387776888e-06,
      "loss": 1.3801,
      "step": 7170
    },
    {
      "epoch": 2.8742994395516415,
      "grad_norm": 0.6072707176208496,
      "learning_rate": 2.1016813450760607e-06,
      "loss": 1.3785,
      "step": 7180
    },
    {
      "epoch": 2.878302642113691,
      "grad_norm": 0.49706903100013733,
      "learning_rate": 2.0349613023752335e-06,
      "loss": 1.5712,
      "step": 7190
    },
    {
      "epoch": 2.8823058446757406,
      "grad_norm": 0.5534418821334839,
      "learning_rate": 1.9682412596744063e-06,
      "loss": 1.3928,
      "step": 7200
    },
    {
      "epoch": 2.8863090472377904,
      "grad_norm": 0.5235874652862549,
      "learning_rate": 1.9015212169735788e-06,
      "loss": 1.4641,
      "step": 7210
    },
    {
      "epoch": 2.89031224979984,
      "grad_norm": 0.6105703115463257,
      "learning_rate": 1.8348011742727516e-06,
      "loss": 1.4109,
      "step": 7220
    },
    {
      "epoch": 2.8943154523618895,
      "grad_norm": 0.6187899112701416,
      "learning_rate": 1.7680811315719244e-06,
      "loss": 1.4868,
      "step": 7230
    },
    {
      "epoch": 2.8983186549239393,
      "grad_norm": 2.2680201530456543,
      "learning_rate": 1.701361088871097e-06,
      "loss": 1.3828,
      "step": 7240
    },
    {
      "epoch": 2.9023218574859886,
      "grad_norm": 0.5367236137390137,
      "learning_rate": 1.6346410461702697e-06,
      "loss": 1.3703,
      "step": 7250
    },
    {
      "epoch": 2.9063250600480384,
      "grad_norm": 0.5518724322319031,
      "learning_rate": 1.5679210034694425e-06,
      "loss": 1.3831,
      "step": 7260
    },
    {
      "epoch": 2.910328262610088,
      "grad_norm": 0.5051483511924744,
      "learning_rate": 1.501200960768615e-06,
      "loss": 1.4491,
      "step": 7270
    },
    {
      "epoch": 2.914331465172138,
      "grad_norm": 0.5029087662696838,
      "learning_rate": 1.4344809180677876e-06,
      "loss": 1.5434,
      "step": 7280
    },
    {
      "epoch": 2.9183346677341873,
      "grad_norm": 0.4899919927120209,
      "learning_rate": 1.3677608753669602e-06,
      "loss": 1.4032,
      "step": 7290
    },
    {
      "epoch": 2.922337870296237,
      "grad_norm": 0.6464362144470215,
      "learning_rate": 1.301040832666133e-06,
      "loss": 1.4702,
      "step": 7300
    },
    {
      "epoch": 2.9263410728582864,
      "grad_norm": 0.6311112642288208,
      "learning_rate": 1.2343207899653055e-06,
      "loss": 1.3582,
      "step": 7310
    },
    {
      "epoch": 2.930344275420336,
      "grad_norm": 0.553784966468811,
      "learning_rate": 1.1676007472644783e-06,
      "loss": 1.458,
      "step": 7320
    },
    {
      "epoch": 2.934347477982386,
      "grad_norm": 0.5059346556663513,
      "learning_rate": 1.1008807045636509e-06,
      "loss": 1.4671,
      "step": 7330
    },
    {
      "epoch": 2.9383506805444357,
      "grad_norm": 0.6806282997131348,
      "learning_rate": 1.0341606618628237e-06,
      "loss": 1.4742,
      "step": 7340
    },
    {
      "epoch": 2.942353883106485,
      "grad_norm": 0.5311003923416138,
      "learning_rate": 9.674406191619964e-07,
      "loss": 1.3342,
      "step": 7350
    },
    {
      "epoch": 2.946357085668535,
      "grad_norm": 0.6562357544898987,
      "learning_rate": 9.007205764611689e-07,
      "loss": 1.4964,
      "step": 7360
    },
    {
      "epoch": 2.9503602882305846,
      "grad_norm": 0.6369057893753052,
      "learning_rate": 8.340005337603417e-07,
      "loss": 1.3872,
      "step": 7370
    },
    {
      "epoch": 2.954363490792634,
      "grad_norm": 0.5255323648452759,
      "learning_rate": 7.672804910595143e-07,
      "loss": 1.4194,
      "step": 7380
    },
    {
      "epoch": 2.9583666933546837,
      "grad_norm": 0.6217485666275024,
      "learning_rate": 7.00560448358687e-07,
      "loss": 1.3658,
      "step": 7390
    },
    {
      "epoch": 2.9623698959167335,
      "grad_norm": 0.4593951106071472,
      "learning_rate": 6.338404056578597e-07,
      "loss": 1.4441,
      "step": 7400
    },
    {
      "epoch": 2.9663730984787833,
      "grad_norm": 0.6476554274559021,
      "learning_rate": 5.671203629570322e-07,
      "loss": 1.339,
      "step": 7410
    },
    {
      "epoch": 2.9703763010408326,
      "grad_norm": 0.5774073004722595,
      "learning_rate": 5.00400320256205e-07,
      "loss": 1.4643,
      "step": 7420
    },
    {
      "epoch": 2.9743795036028824,
      "grad_norm": 0.5032845735549927,
      "learning_rate": 4.3368027755537764e-07,
      "loss": 1.4126,
      "step": 7430
    },
    {
      "epoch": 2.9783827061649317,
      "grad_norm": 0.5142568945884705,
      "learning_rate": 3.669602348545503e-07,
      "loss": 1.4627,
      "step": 7440
    },
    {
      "epoch": 2.9823859087269815,
      "grad_norm": 0.6369548439979553,
      "learning_rate": 3.00240192153723e-07,
      "loss": 1.4193,
      "step": 7450
    },
    {
      "epoch": 2.9863891112890313,
      "grad_norm": 0.5689389109611511,
      "learning_rate": 2.3352014945289568e-07,
      "loss": 1.3889,
      "step": 7460
    },
    {
      "epoch": 2.990392313851081,
      "grad_norm": 0.4987519383430481,
      "learning_rate": 1.6680010675206832e-07,
      "loss": 1.3594,
      "step": 7470
    },
    {
      "epoch": 2.9943955164131304,
      "grad_norm": 0.4789500832557678,
      "learning_rate": 1.00080064051241e-07,
      "loss": 1.3664,
      "step": 7480
    },
    {
      "epoch": 2.99839871897518,
      "grad_norm": 0.5223563313484192,
      "learning_rate": 3.3360021350413665e-08,
      "loss": 1.4741,
      "step": 7490
    }
  ],
  "logging_steps": 10,
  "max_steps": 7494,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5714575031730176e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}

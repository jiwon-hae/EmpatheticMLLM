{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CJhZ2QPF9msa",
        "outputId": "a29f552e-801a-4505-f48b-b7820bc6a53c"
      },
      "id": "CJhZ2QPF9msa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.11/dist-packages (1.90.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.24.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (5.29.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (24.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (3.31.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.1.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (4.13.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0->google-cloud-aiplatform) (2.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import vertexai\n",
        "\n",
        "from vertexai.batch_prediction import BatchPredictionJob\n",
        "print(\"Code is correct\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzxJ-FG39vCv",
        "outputId": "658af0c3-0fea-4bd9-d460-a658978adb42"
      },
      "id": "nzxJ-FG39vCv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code is correct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login --no-launch-browser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6VCvwTQ9zsl",
        "outputId": "e245ce09-9eb4-4972-a133-6c26d85ba7e3"
      },
      "id": "r6VCvwTQ9zsl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=V08BQfSf5iJ44WFVAXfk7DNEA8YmFr&prompt=consent&token_usage=remote&access_type=offline&code_challenge=CLCiaa7pawaZWJ50B1CYX_ZtJ1KCb0yNpLmDJ4kxIrs&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0Ab_5qlm0MkMST34MXXtkgCuvazb14zG1tkvRXb2F6-VLHGPi5trSW4tTMV_hl7H3AYsnzg\n",
            "\n",
            "You are now logged in as [zsdaniel@usc.edu].\n",
            "Your current project is [None].  You can change this setting by running:\n",
            "  $ gcloud config set project PROJECT_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOPDhMlS-BH_",
        "outputId": "2291b3f9-bc53-44a5-8b8f-ebe31fc040fb"
      },
      "id": "JOPDhMlS-BH_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=WlQGFfmCxRMC9bl2K3bPLFZoFhCwLo&prompt=consent&token_usage=remote&access_type=offline&code_challenge=PM8oCgkEHJuBCC9heKizYlXGIOzRXbaSX7RKGQBLFp4&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0Ab_5qlm7wACLWGxLRJWvoIiynsEehBDfChFzmae-F_1kyIJcJ6pBcSe7lagsL8d61AF2hQ\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project csci-535-project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwTO3w4S-J48",
        "outputId": "a40a7ef1-81f6-4050-d425-ea4ab0fc2674"
      },
      "id": "QwTO3w4S-J48",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mWARNING:\u001b[0m Your active project does not match the quota project in your local Application Default Credentials file. This might result in unexpected quota issues.\n",
            "\n",
            "To update your Application Default Credentials quota project, use the `gcloud auth application-default set-quota-project` command.\n",
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default set-quota-project csci-535-project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUKM9HlOB5Ml",
        "outputId": "7716b746-2646-4cdf-f04f-a729d94e9e4d"
      },
      "id": "YUKM9HlOB5Ml",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"csci-535-project\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdf7ac1c",
      "metadata": {
        "id": "fdf7ac1c"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "PROJECT_ID = \"csci-535-project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "871b7782",
      "metadata": {
        "id": "871b7782"
      },
      "outputs": [],
      "source": [
        "import vertexai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab1c1bc",
      "metadata": {
        "id": "fab1c1bc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset CSVs\n",
        "train_df = pd.read_csv(\"data/train_sent_emo.csv\")\n",
        "dev_df = pd.read_csv(\"data/dev_sent_emo.csv\")\n",
        "test_df = pd.read_csv(\"data/test_sent_emo.csv\")\n",
        "\n",
        "# Show first few rows\n",
        "# train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b343ba12",
      "metadata": {
        "id": "b343ba12"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client(\n",
        "    vertexai=True, project=PROJECT_ID, location=\"us-central1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d357cca6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d357cca6",
        "outputId": "4a42259b-408d-4f2e-ce3f-e9d54a8c288b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train inputs: 9989\n",
            "Dev inputs: 1109\n",
            "Test inputs: 2610\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def create_formatted_inputs(df):\n",
        "    dialogues = defaultdict(list)\n",
        "\n",
        "    # Group utterances by dialogue\n",
        "    for _, row in df.iterrows():\n",
        "        dialogues[row[\"Dialogue_ID\"]].append((row[\"Speaker\"], row[\"Utterance\"], row[\"Emotion\"]))\n",
        "\n",
        "    # Convert to list format for easy processing\n",
        "    dialogues = list(dialogues.values())\n",
        "\n",
        "    # Generate formatted inputs with context\n",
        "    formatted_inputs = []\n",
        "    for dialogue in dialogues:\n",
        "        context = \"\"\n",
        "        for idx, (speaker, utterance, emotion) in enumerate(dialogue):\n",
        "            context += f\"{speaker}: {utterance}\\n\"\n",
        "\n",
        "            last_speaker = speaker\n",
        "            # Determine next speaker based on alternation if possible\n",
        "            if idx + 1 < len(dialogue):\n",
        "                next_speaker = dialogue[idx + 1][0]\n",
        "            else:\n",
        "                next_speaker = speaker  # Default to last speaker if no next available\n",
        "\n",
        "            prompt = r\"\"\"### INSTRUCTIONS ###\n",
        "Continue the conversation by generating **only the next line** spoken by the indicated character.\n",
        "Your response must be empathetic, showing understanding or emotional attunement to the preceding dialogue.\n",
        "\n",
        "### EXAMPLE ###\n",
        "\n",
        "=== DIALOGUE HISTORY ===\n",
        "Rachel: Hey!\n",
        "Ross: Hi!\n",
        "Rachel: What are you doing here?\n",
        "Ross: Ah y'know, this building is on my paper route so I...\n",
        "Rachel: Oh.\n",
        "Ross: Hi.\n",
        "Rachel: Hi.\n",
        "Ross: How'd did it go?\n",
        "Rachel: Oh well, the woman I interviewed with was pretty tough, but y'know thank God Mark coached me, because once I started talking about the fall line, she got all happy and wouldn't shut up.\n",
        "Ross:\n",
        "\n",
        "=== RESPONSE ===\n",
        "That sounds like a huge relief.\n",
        "\n",
        "### TASK ###\n",
        "\n",
        "=== DIALOGUE HISTORY ===\n",
        "{dialogue_hist}\n",
        "\n",
        "=== RESPONSE ===\n",
        "            \"\"\"\n",
        "\n",
        "            # full_input = (\n",
        "            #     \"### TASK ###\\n\"\n",
        "            #     \"Continue the conversation by generating **only one line** as the next speaker.\\n\"\n",
        "            #     \"This response should be **empathetic**, acknowledging or reflecting the emotional tone of the previous dialogue.\\n\"\n",
        "            #     \"DO NOT generate multiple lines.\\n\"\n",
        "            #     \"DO NOT summarize, analyze, or explain.\\n\"\n",
        "            #     \"Only generate one line and nothing more.\\n\\n\"\n",
        "            #     \"### DIALOGUE HISTORY ###\\n\"\n",
        "            #     f\"{context.strip()}\\n\"\n",
        "            #     f\"{next_speaker}:\"\n",
        "            # )\n",
        "\n",
        "            formatted_inputs.append(prompt.format(dialogue_hist=f\"{context}{next_speaker}:\"))\n",
        "\n",
        "    return formatted_inputs\n",
        "\n",
        "# Apply to each split\n",
        "train_formatted_inputs = create_formatted_inputs(train_df)\n",
        "dev_formatted_inputs = create_formatted_inputs(dev_df)\n",
        "test_formatted_inputs = create_formatted_inputs(test_df)\n",
        "\n",
        "print(f\"Train inputs: {len(train_formatted_inputs)}\")\n",
        "print(f\"Dev inputs: {len(dev_formatted_inputs)}\")\n",
        "print(f\"Test inputs: {len(test_formatted_inputs)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_formatted_inputs[11])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2oB3Q5bibQJ",
        "outputId": "a54c4e6f-83a0-485c-9f66-f9afaf7f344e"
      },
      "id": "C2oB3Q5bibQJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### INSTRUCTIONS ###\n",
            "Continue the conversation by generating **only the next line** spoken by the indicated character.\n",
            "Your response must be empathetic, showing understanding or emotional attunement to the preceding dialogue.\n",
            "\n",
            "### EXAMPLE ###\n",
            "\n",
            "=== DIALOGUE HISTORY ===\n",
            "Rachel: Hey!\n",
            "Ross: Hi!\n",
            "Rachel: What are you doing here?\n",
            "Ross: Ah y'know, this building is on my paper route so I...\n",
            "Rachel: Oh.\n",
            "Ross: Hi.\n",
            "Rachel: Hi.\n",
            "Ross: How'd did it go?\n",
            "Rachel: Oh well, the woman I interviewed with was pretty tough, but y'know thank God Mark coached me, because once I started talking about the fall line, she got all happy and wouldn't shut up.\n",
            "Ross:\n",
            "\n",
            "=== RESPONSE ===\n",
            "That sounds like a huge relief.\n",
            "\n",
            "### TASK ###\n",
            "\n",
            "=== DIALOGUE HISTORY ===\n",
            "Chandler: also I was the point person on my company’s transition from the KL-5 to GR-6 system.\n",
            "The Interviewer: You must’ve had your hands full.\n",
            "Chandler: That I did. That I did.\n",
            "The Interviewer: So let’s talk a little bit about your duties.\n",
            "Chandler: My duties?  All right.\n",
            "The Interviewer: Now you’ll be heading a whole division, so you’ll have a lot of duties.\n",
            "Chandler: I see.\n",
            "The Interviewer: But there’ll be perhaps 30 people under you so you can dump a certain amount on them.\n",
            "Chandler: Good to know.\n",
            "The Interviewer: We can go into detail\n",
            "Chandler: No don’t I beg of you!\n",
            "The Interviewer: All right then, we’ll have a definite answer for you on Monday, but I think I can say with some confidence, you’ll fit in well here.\n",
            "Chandler:\n",
            "\n",
            "=== RESPONSE ===\n",
            "            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gemini-2.0-flash-lite\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=model,\n",
        "    contents=train_formatted_inputs[11],\n",
        "    config=types.GenerateContentConfig(\n",
        "        max_output_tokens=500,\n",
        "        temperature=0.7\n",
        "    )\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_9h82S6BEx3",
        "outputId": "28b4601e-0a51-43ab-ec52-c42907f6e82f"
      },
      "id": "N_9h82S6BEx3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, wow. That’s… that’s great to hear.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, csv\n",
        "from tqdm import tqdm\n",
        "from typing import Any\n",
        "from google.genai.types import GenerateContentConfig\n",
        "\n",
        "# Your existing backoff method, updated to support config\n",
        "def generate_with_backoff(prompt: str, config: GenerateContentConfig, max_retries: int = 5, backoff_factor: int = 2) -> str:\n",
        "    attempt = 0\n",
        "    while attempt < max_retries:\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=\"gemini-2.0-flash-lite\",\n",
        "                contents=[prompt],\n",
        "                config=config\n",
        "            )\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            attempt += 1\n",
        "            delay = backoff_factor ** attempt\n",
        "            print(f\"Error encountered: {e}. Retrying in {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "    raise Exception(\"Max retries reached. Failed to generate content.\")"
      ],
      "metadata": {
        "id": "a-qDYdtsCrQJ"
      },
      "id": "a-qDYdtsCrQJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = GenerateContentConfig(\n",
        "    max_output_tokens=500,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "def generate_and_save_responses(formatted_inputs, csv_filename):\n",
        "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header\n",
        "        writer.writerow(['Prompt', 'Response'])\n",
        "\n",
        "        # Generate responses and write to CSV as they are generated\n",
        "        for prompt in tqdm(formatted_inputs, desc=f\"Generating responses for {csv_filename}\"):\n",
        "            response_text = generate_with_backoff(prompt, config=config)\n",
        "            response_text_stripped = response_text.strip()\n",
        "\n",
        "            # Write the prompt and the response to the CSV\n",
        "            writer.writerow([prompt, response_text_stripped])\n",
        "\n",
        "# Generate and save responses for train, dev, and test\n",
        "generate_and_save_responses(train_formatted_inputs, 'train_targets.csv')\n",
        "generate_and_save_responses(dev_formatted_inputs, 'dev_targets.csv')\n",
        "generate_and_save_responses(test_formatted_inputs, 'test_targets.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W26IbhTDC30M",
        "outputId": "8e119136-4294-4c4f-caae-c0ce7a8263bc"
      },
      "id": "W26IbhTDC30M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating responses for train_targets.csv: 100%|██████████| 9989/9989 [1:11:12<00:00,  2.34it/s]\n",
            "Generating responses for dev_targets.csv: 100%|██████████| 1109/1109 [07:45<00:00,  2.38it/s]\n",
            "Generating responses for test_targets.csv: 100%|██████████| 2610/2610 [18:28<00:00,  2.35it/s]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}